---
title: "\U0001F39A Comparing Proportions"
author: "Arvind Venkatadri"
date: 28/11/2022
lastmod: "2023-01-20"
links:
- icon: circle
  icon_pack: fas
  name: Orange Tutorial
  url: "labs/Data-Analytics/categorical.ows"
- icon: sun
  icon_pack: fas
  name: Radiant
  url: "labs/Data-Analytics/categorical.rda"
- icon: r-project
  icon_pack: fab
  name: R Tutorial
  url: "labs/Data-Analytics/categorical.html"
- icon: database
  icon_pack: fas
  name: Sample Datasets
  url: "labs/Data-Analytics/data/cat-data.zip"
output:
  html_document:
    toc_float: yes
    theme: flatly
    highlight: tango
    toc: yes
    code_folding: show
    code_download: yes
    number_sections: yes
keywords: Statistics ; Tests; p-value; Feynman Technique
abstract:  This module is intended to assist with making statistically significant insights that drive business decisions. This document deals with the basics of stats. The method followed is that of Jonas Lindoloev, wherein every stat test is treated as a linear model y = mx + c.
editor_options: 
  chunk_output_type: inline
  markdown: 
    wrap: 72
---



<div id="independence-of-categorical-variables" class="section level3">
<h3>Independence of Categorical Variables</h3>
<p>R provides for several tests of independence of <strong>CATEGORICAL</strong> variables.
These are the chi-square, Fisher exact and Cochran-Mantel- Haenszel tests.</p>
<div id="pearson-chi-square-test" class="section level4">
<h4>Pearson Chi-Square Test</h4>
<p>Chi square test needs a frequency table to be created first and works on two variables in the Table to decide if they are independent or not. <em>A crosstable is needed since the variables are categorical and need counts or scores to check for their independence.</em></p>
<pre class="r"><code>myxtable &lt;- xtabs(data = Arthritis,formula = ~ Treatment + Improved)
myxtable2 &lt;- xtabs(data = Arthritis, ~ Improved + Sex)

# remember nothing on the LHS unless it is already in terms of frequency

stats::chisq.test(myxtable) # Checks if variables are independent. So P value needs to be high for independence</code></pre>
<pre><code>## 
## 	Pearson&#39;s Chi-squared test
## 
## data:  myxtable
## X-squared = 13.055, df = 2, p-value = 0.001463</code></pre>
<pre class="r"><code>stats::chisq.test(myxtable2)</code></pre>
<pre><code>## Warning in stats::chisq.test(myxtable2): Chi-squared approximation may be
## incorrect</code></pre>
<pre><code>## 
## 	Pearson&#39;s Chi-squared test
## 
## data:  myxtable2
## X-squared = 4.8407, df = 2, p-value = 0.08889</code></pre>
<p>Since the p-value of the Pearson Chisquare Test is very small, the variables Treatment and Improved are NOT independent and are therefore related.</p>
<p>With Improved and Sex, there is no dependence. Here the p-value is more than 5% so it is likely that these variables are independent.</p>
</div>
<div id="fisher-exact-test" class="section level4">
<h4>Fisher Exact Test</h4>
<p>The Fisher exact test uses a Contingency Table, as with a Pearson ChiSquare Test.</p>
<pre class="r"><code>stats::fisher.test(myxtable)</code></pre>
<pre><code>## 
## 	Fisher&#39;s Exact Test for Count Data
## 
## data:  myxtable
## p-value = 0.001393
## alternative hypothesis: two.sided</code></pre>
<pre class="r"><code>stats::fisher.test(myxtable2)</code></pre>
<pre><code>## 
## 	Fisher&#39;s Exact Test for Count Data
## 
## data:  myxtable2
## p-value = 0.1094
## alternative hypothesis: two.sided</code></pre>
<ul>
<li>Treatment + Improved: The p-value is much smaller than 5% so these two variables are NOT independent. Hence Treatment and Improved are dependent.
-Treatment + Sex: p-value is pretty high, so Treatment and Sex are independent.</li>
</ul>
</div>
<div id="cochran-mantel-haenszel-test" class="section level4">
<h4>Cochran-Mantel-Haenszel Test</h4>
<p>Another test for Independence is the Cochran-Mantel-Haenszel test: This test uses a <em>3D Contingency Table</em> and checks for the null hypothesis that <em>the first two variables are independent at every stratum of the third</em>. So we choose:</p>
<ul>
<li>Treatment + Improved vs Sex</li>
</ul>
<pre class="r"><code>myxtable3 &lt;- xtabs(data = Arthritis, ~ Treatment + Improved + Sex)
stats::mantelhaen.test(myxtable3)</code></pre>
<pre><code>## 
## 	Cochran-Mantel-Haenszel test
## 
## data:  myxtable3
## Cochran-Mantel-Haenszel M^2 = 14.632, df = 2, p-value = 0.0006647</code></pre>
<p>Hence Treatment and Improved are NOT independent across all values of Sex. Hence, Treated individuals reported improvement more often than those receiving Placebos, after controlling for Sex.</p>
</div>
<div id="associations-between-categorical-variables" class="section level4">
<h4>Associations between categorical variables</h4>
<p>When Tests for Independence fail and the variables are NOT independent, we need to explore <strong>the extent of the association.</strong></p>
<p>The <em>vcd</em> package allows us to look at these aspects:</p>
<ul>
<li>“phi” coefficient</li>
<li>Contingency coefficient</li>
<li>Cramer’s V ( for a 2D table) ## Phew !!!</li>
</ul>
<p>We know Treatment and Improved are NOT independent, so lets look at these cat-variables:</p>
<pre class="r"><code>vcd::assocstats(myxtable)</code></pre>
<pre><code>##                     X^2 df  P(&gt; X^2)
## Likelihood Ratio 13.530  2 0.0011536
## Pearson          13.055  2 0.0014626
## 
## Phi-Coefficient   : NA 
## Contingency Coeff.: 0.367 
## Cramer&#39;s V        : 0.394</code></pre>
<pre class="r"><code>vcd::assocstats(myxtable2)</code></pre>
<pre><code>##                     X^2 df P(&gt; X^2)
## Likelihood Ratio 5.0131  2 0.081550
## Pearson          4.8407  2 0.088891
## 
## Phi-Coefficient   : NA 
## Contingency Coeff.: 0.233 
## Cramer&#39;s V        : 0.24</code></pre>
<p>Larger magnitudes mean larger associations. But I can’t tell in absolute terms what is a “good number”.</p>
<p>I wonder why the Phi Coefficient is NA: oh, it is computed only for 2 x 2 tables !!</p>
</div>
</div>
<div id="a-workflow-in-orange" class="section level2">
<h2>A Workflow in Orange</h2>
</div>
<div id="a-workflow-in-radiant" class="section level2">
<h2>A Workflow in Radiant</h2>
</div>
<div id="a-workflow-in-r" class="section level2">
<h2>A Workflow in R</h2>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<ol style="list-style-type: decimal">
<li><em>Common statistical tests are linear models (or: how to teach
stats)</em> by <a href="https://lindeloev.github.io/tests-as-linear/">Jonas Kristoffer
Lindeløv</a></li>
<li><a href="https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.pdf">CheatSheet</a></li>
<li><em>Common statistical tests are linear models: a work through</em> by
<a href="https://steverxd.github.io/Stat_tests/">Steve Doogue</a></li>
<li><a href="https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/">Jeffrey Walker “Elements of Statistical Modeling for Experimental
Biology”</a></li>
<li>Text: Diez, David M &amp; Barr, Christopher D &amp; Çetinkaya-Rundel, Mine:
<a href="https://www.openintro.org/book/os/">OpenIntro Statistics</a></li>
<li>Modern Statistics with R: From wrangling and exploring data to
inference and predictive modelling by <a href="http://www.modernstatisticswithr.com/">Måns
Thulin</a></li>
</ol>
</div>
<div id="structure-of-this-document" class="section level1">
<h1>Structure of this document</h1>
<p>We will follow the following structure: Each kind of Test is described
in a separate Chapter. The Test <em>Model</em> is laid out in formula
<span class="math inline">\(y = mx + c\)</span> and in <em>Code</em>.</p>
<p>The Structure looks like this:</p>
<div id="test" class="section level2 tabset">
<h2>Test</h2>
<div id="model" class="section level3">
<h3>Model</h3>
<p>Explanation, formula etc.</p>
</div>
<div id="code" class="section level3">
<h3>Code</h3>
<p>With Toy Data; Graphs</p>
</div>
<div id="example" class="section level3">
<h3>Example</h3>
<p>With another “real world” data set; Graphs</p>
</div>
</div>
</div>
<div id="data" class="section level1">
<h1>Data</h1>
<div id="sample-values" class="section level2">
<h2>Sample Values</h2>
<p>Most examples in this exposition are based on three “imaginary” samples,
<span class="math inline">\(x, y, y2\)</span>. Each is normally distributed and made up of 50 observations.</p>
<p>We start by creating a function that will allow us to produce samples of
a given size (N) with a specified mean (mu) and standard deviation (sd):
Note: this gives a <em>matrix</em> of numbers, as opposed to a vector using
<code>rnorm</code> by itself. The data are created both in vector form and tibble
form for flexibility of use in diverse packages and formulae in what
follows.</p>
<pre class="r"><code>rnorm_fixed  &lt;- function(N, mu = 0, sd = 1) {
  scale(rnorm(N))* sd + mu
}</code></pre>
<p>We create three variables: x ( explanatory) and y, y2 ( dependent ).</p>
<pre class="r"><code>set.seed(40) # for replication

# Data as vectors ( for t.tests etc)
x &lt;- rnorm_fixed(50, mu = 0.0, sd = 1) #explanatory
y &lt;- rnorm_fixed(50, mu = 0.3, sd = 2) # dependent #1
y2 &lt;- rnorm_fixed(50, mu = 0.5, sd = 1.5) # dependent #2

# Make a tibble with all variables
mydata_wide &lt;- tibble(x = x, y = y, y2 = y2)

# Long form data
mydata_long &lt;- 
  mydata_wide %&gt;%
  pivot_longer(., cols = c(x,y,y2), 
               names_to = &quot;group&quot;, 
               values_to = &quot;value&quot;)

# Long form data with only dependent variables
mydata_long_y &lt;- 
  mydata_wide %&gt;% 
  select(-x) %&gt;% 
  pivot_longer(., cols = c(y,y2), 
               names_to = &quot;group&quot;, 
               values_to = &quot;value&quot;)
mydata_wide</code></pre>
<pre><code>## # A tibble: 50 × 3
##     x[,1]  y[,1] y2[,1]
##     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1  0.427  1.98   0.103
##  2  0.444  1.27  -0.281
##  3 -0.828 -0.944  0.624
##  4 -0.799  0.103  5.43 
##  5 -0.323  2.19   0.168
##  6 -1.24   0.192 -0.549
##  7 -1.36   4.81   0.309
##  8  1.62   1.55  -0.990
##  9 -0.292  3.36  -0.172
## 10 -1.25   1.92  -0.158
## # … with 40 more rows</code></pre>
<pre class="r"><code>mydata_long</code></pre>
<pre><code>## # A tibble: 150 × 2
##    group value[,1]
##    &lt;chr&gt;     &lt;dbl&gt;
##  1 x         0.427
##  2 y         1.98 
##  3 y2        0.103
##  4 x         0.444
##  5 y         1.27 
##  6 y2       -0.281
##  7 x        -0.828
##  8 y        -0.944
##  9 y2        0.624
## 10 x        -0.799
## # … with 140 more rows</code></pre>
<pre class="r"><code>mydata_long_y</code></pre>
<pre><code>## # A tibble: 100 × 2
##    group value[,1]
##    &lt;chr&gt;     &lt;dbl&gt;
##  1 y         1.98 
##  2 y2        0.103
##  3 y         1.27 
##  4 y2       -0.281
##  5 y        -0.944
##  6 y2        0.624
##  7 y         0.103
##  8 y2        5.43 
##  9 y         2.19 
## 10 y2        0.168
## # … with 90 more rows</code></pre>
</div>
<div id="signed-rank-values" class="section level2">
<h2>“Signed Rank” Values</h2>
<p>Most statistical tests use the <strong>actual values</strong> of the data variables.
However, in some <em>non-parametric</em> statistical tests, the data are used
in <strong>rank-transformed</strong> sense/order. In some cases the <strong>signed-rank</strong>
of the data values is used instead of the data itself.</p>
<p>Signed Rank is calculated as follows:<br />
1. Take the absolute value of each observation in a sample<br />
2. Place the <u><em>ranks</em></u> in order of (absolute magnitude). The
smallest number has <em>rank = 1</em> and so on.<br />
3. Give each of the ranks the sign of the original observation ( + or -
)</p>
<pre class="r"><code>signed_rank &lt;- function(x) {sign(x) * rank(abs(x))}</code></pre>
</div>
<div id="plotting-original-and-signed-rank-data" class="section level2">
<h2>Plotting Original and Signed Rank Data</h2>
<p>A quick plot:</p>
<pre class="r"><code>p1 &lt;- ggplot(mydata_long,aes(x = group, y = value)) +
  geom_jitter(width = 0.02, height = 0,aes(colour = group), size = 4) +
  geom_segment(data = mydata_wide, aes(y = 0, yend = 0, 
                                       x = .75, 
                                       xend = 1.25 )) + 
  geom_text(aes(x = 1, y = 0.5, label = &quot;0&quot;)) +
  geom_segment(data = mydata_wide, aes(y = 0.3, yend = 0.3, 
                                       x = 1.75 , 
                                       xend = 2.25 )) + 
  geom_text(aes(x = 2, y = 0.6, label = &quot;0.3&quot;)) +
  geom_segment(data = mydata_wide, aes(y = 0.5, yend = 0.5, 
                                       x = 2.75, 
                                       xend = 3.25 )) + 
  geom_text(aes(x = 3, y = 0.8, label = &quot;0.5&quot;)) +
  labs(title = &quot;Original Data&quot;) +
  ylab(&quot;Response Variable&quot;)

p2 &lt;- mydata_long %&gt;% 
  group_by(group) %&gt;% 
  mutate( s_value = signed_rank(value)) %&gt;% 
  ggplot(., aes(x = group, y = s_value)) + 
  geom_jitter(width = 0.02, height = 0,aes(colour = group), size = 4) + 
  stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, colour = &quot;red&quot;, 
               size = 8) + 
  labs(title = &quot;Signed Rank of Data&quot;) +
  ylab(&quot;Signed Rank of Response Variable&quot;)

patchwork::wrap_plots(p1,p2, nrow = 1, guides = &quot;collect&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/data_plots-1.png" width="672" /></p>
</div>
<div id="how-does-sign-rank-data-work" class="section level2">
<h2>How does Sign-Rank data work?</h2>
<p>TBD: need to add some explanation here.</p>
</div>
</div>
<div id="the-linear-regression-model" class="section level1 tabset">
<h1>The Linear ( Regression ) Model</h1>
<p>The premise here is that many common statistical tests are special cases
of the linear model.</p>
<p>A linear model estimates the relationship between one <em>continuous</em> or
<em>ordinal</em> variable (dependent variable or “response” ) and one or more
other variables ( explanatory variable or “predictors” ). It is assumed
that the relationship is linear:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1 *x
\]</span> <span class="math inline">\(\beta_0\)</span> is the <em>intercept</em> and <span class="math inline">\(\beta_1\)</span> is the slope of the linear
fit, that <strong>predicts</strong> the value of y based the value of x. Each
prediction leaves a small “residual” error between the actual and
predicted values. <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are calculated based on
minimizing the <em>sum of square</em>s of these residuals, and hence this
method is called “ordinary least squares” regression.</p>
<div class="figure">
<img src="OLS.png" alt="" />
<p class="caption">Least Squares</p>
</div>
<p>The net <em>area</em> of all the shaded squares is minimized in the calculation
of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. It is also possible that there is more than
one explanatory variable: this is <strong>multiple regression.</strong></p>
<p><span class="math display">\[
y = \beta_0 + \beta_1*x_1 + \beta_2*x_2 ...+ \beta_n*x_n
\]</span></p>
<p>where each of the <span class="math inline">\(\beta_i\)</span> are slopes defining the relationship between
y and <span class="math inline">\(x_i\)</span>. Together, the RHS of that equation defines an n-dimensional
<em>plane</em>.</p>
<p>As per Lindoloev, many statistical tests, going from one-sample t-tests
to two-way ANOVA, are special cases of this system.</p>
<p>Also see <a href="https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/intro-linear-models.html#a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables">Jeffrey Walker “A
linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables”</a></p>
<div id="linear-models-as-hypothesis-tests" class="section level2">
<h2>Linear Models as Hypothesis Tests</h2>
<p>Using linear models is based on the idea of <strong>Testing of Hypotheses</strong>.
The Hypothesis Testing method typically defines a NULL Hypothesis where
the statements read as “<strong>there is no relationship</strong>” between the
variables at hand, explanatory and responses. The Alternative Hypothesis
typically states that there <em>is</em> a relationship between the variables.</p>
<p>Accordingly, in fitting a linear model, we follow the process as
follows:</p>
<ol style="list-style-type: decimal">
<li>Make the following hypotheses: <span class="math display">\[
y = \beta_0 + \beta_1 *x \\
NULL\ Hypothesis\ H_0 =&gt; x\ and\ y\ are\ unrelated.\ (\beta_1 = 0)
\]</span> <span class="math display">\[
y = \beta_0 + \beta_1 *x \\
Alternate\ Hypothesis\ H_1 =&gt; x\ and\ y\ are\ linearly\ related\ (\beta_1 \ne 0)
\]</span></li>
<li>We “assume” that <span class="math inline">\(H_0\)</span> is true.</li>
<li>We calculate <span class="math inline">\(\beta_1\)</span>.</li>
<li>We then find probability <strong>p</strong> that [<span class="math inline">\(\beta_1 = Estimated\ Value\)</span>]
<strong>when the NULL Hypothesis</strong> is <strong>assumed</strong> TRUE. This is the
<strong>p-value</strong>. If that probability is <strong>p&gt;=0.05</strong>, we say we “cannot
reject” <span class="math inline">\(H_0\)</span> and there is unlikely to be significant linear
relationship.</li>
</ol>
<p>However, if <strong>p&lt;= 0.05</strong> can we reject the NULL hypothesis, and say
that there could be a significant linear relationship,because
<span class="math inline">\(\beta_1 = Estimated\ Value\)</span> by mere chance under <span class="math inline">\(H_0\)</span> is very small.</p>
<p>Pheeew !!</p>
</div>
<div id="linear-models-in-r" class="section level2">
<h2>Linear Models in R</h2>
<p><code>lm()</code> is the function to create linear models in R. In R we are lazy
and write :</p>
<p><span class="math display">\[
y \sim 1 + x\\
which\ reads\ like\\
y = 1*number + x* another\ number
\]</span></p>
<p>Note: there are very many ways in which linear models can be coded in R.
See <a href="https://cran.r-project.org/doc/contrib/Ricci-refcard-regression.pdf">Vito Ricci on
CRAN.</a></p>
<pre class="r"><code># using lm()
lm(y ~ 1 + x, data = mydata_wide) %&gt;% 
  summary() %&gt;%   
  print(digits = 5)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ 1 + x, data = mydata_wide)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.93980 -1.09967  0.12548  1.27904  3.88372 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.30000    0.27799  1.0792   0.2859
## x           -0.46355    0.28081 -1.6507   0.1053
## 
## Residual standard error: 1.9657 on 48 degrees of freedom
## Multiple R-squared:  0.05372,	Adjusted R-squared:  0.034006 
## F-statistic:  2.725 on 1 and 48 DF,  p-value: 0.10532</code></pre>
<p>Since the <em>p-value</em> is &gt;=0.05, we <em>fail to reject the NULL Hypothesis
that there is no relationship between x and y</em>.</p>
</div>
<div id="assumptions-in-linear-models" class="section level2">
<h2>Assumptions in Linear Models</h2>
<ol style="list-style-type: decimal">
<li><strong>L</strong>: <span class="math inline">\(\color{blue}{linear}\)</span> relationship</li>
<li><strong>I</strong>: Errors are <strong>independent</strong> (across observations)</li>
<li><strong>N</strong>: y is <span class="math inline">\(\color{red}{normally}\)</span> distributed at each “level”
of x.</li>
<li><strong>E</strong>: equal variance at all levels of x. No <em>heteroscedasticity</em>.
<img src="ols_assumptions.png" alt="OLS Assumptions" /></li>
</ol>
<p>Let us now see which standard statistical tests can be re-formulated as
Linear Models.</p>
</div>
</div>
<div id="tests-for-correlation" class="section level1 tabset">
<h1>Tests for Correlation</h1>
<p>Correlation <strong>r</strong> is a measure of <em>strength</em> and <em>direction</em> of <em>linear
association</em> between two variables. <strong>r</strong> is between [-1,+1], with 0
implying no association/correlation.</p>
<p>From this definition, the <em>linear model</em> lends itself in a
straightforward way as a model to interpret <em>correlation</em>. Intuitively,
the slope of the linear model could be related to the correlation
between y and x.</p>
<p>Now we look at the numbers.</p>
<div id="pearson-correlation" class="section level2 tabset">
<h2>Pearson Correlation</h2>
<div id="model-1" class="section level3">
<h3>Model</h3>
<p>The model for Pearson Correlation tests is exactly the Linear Model:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1 * x
\\
H_0: \beta_1 = 0
\]</span></p>
<p>See the Code section for further insights into the relationship between
the Correlation Score and the Slope of the Linear Model.</p>
</div>
<div id="code-1" class="section level3">
<h3>Code</h3>
<pre class="r"><code># Pearson (built-in test)
cor &lt;- cor.test(y,x,method = &quot;pearson&quot;) %&gt;% 
  broom::tidy() %&gt;% select(estimate, p.value)

# Linear Model
lin &lt;- lm(y ~ 1 + x, data = mydata_wide) %&gt;% 
  broom::tidy() %&gt;% select(estimate, p.value)

# Scaled linear model
lin_scl &lt;- lm(scale(y) ~ 1 + scale(x), data = mydata_wide) %&gt;% 
  broom::tidy() %&gt;% select(estimate, p.value)

print(cor)</code></pre>
<pre><code>## # A tibble: 1 × 2
##   estimate p.value
##      &lt;dbl&gt;   &lt;dbl&gt;
## 1   -0.232   0.105</code></pre>
<pre class="r"><code>print(lin)</code></pre>
<pre><code>## # A tibble: 2 × 2
##   estimate p.value
##      &lt;dbl&gt;   &lt;dbl&gt;
## 1    0.3     0.286
## 2   -0.464   0.105</code></pre>
<pre class="r"><code>print(lin_scl)</code></pre>
<pre><code>## # A tibble: 2 × 2
##    estimate p.value
##       &lt;dbl&gt;   &lt;dbl&gt;
## 1 -9.06e-17   1    
## 2 -2.32e- 1   0.105</code></pre>
<pre class="r"><code># All together
rbind(cor, lin, lin_scl) %&gt;% print()</code></pre>
<pre><code>## # A tibble: 5 × 2
##    estimate p.value
##       &lt;dbl&gt;   &lt;dbl&gt;
## 1 -2.32e- 1   0.105
## 2  3   e- 1   0.286
## 3 -4.64e- 1   0.105
## 4 -9.06e-17   1    
## 5 -2.32e- 1   0.105</code></pre>
<p>Notes: 1. The <em>p-value</em> for Pearson Correlation and that for the <em>slope</em>
in the linear model is the same ( 0.1053 ). Which means we cannot reject
the NULL hypothesis of “no relationship”.</p>
<ol start="2" style="list-style-type: decimal">
<li>Here is the relationship between the slope and correlation:</li>
</ol>
<p><span class="math display">\[
Slope\ \beta_1 = \frac{sd_y}{sd_x} * r
\]</span></p>
<p>When both x and y have the same standard deviation, the slope and
correlation are the same. Here, since x has twice the <code>sd</code> of y, the
ratio of <strong>slope</strong> = -0.4635533 to <strong>r</strong> = -0.2317767 is
0.5. Hence a linear model using <code>scale()</code> for both variables will show
slope = <strong>r</strong>.</p>
<p>Slope_Scaled: -0.2317767 = Correlation: -0.2317767</p>
</div>
<div id="example-1" class="section level3">
<h3>Example</h3>
<p>We choose to look at the <code>gpa_study_hours</code> dataset. It has two numeric
columns <code>gpa</code> and <code>study_hours</code>:</p>
<pre class="r"><code>glimpse(gpa_study_hours)</code></pre>
<pre><code>## Rows: 193
## Columns: 2
## $ gpa         &lt;dbl&gt; 4.000, 3.800, 3.930, 3.400, 3.200, 3.520, 3.680, 3.400, 3.…
## $ study_hours &lt;dbl&gt; 10, 25, 45, 10, 4, 10, 24, 40, 10, 10, 30, 7, 15, 60, 10, …</code></pre>
<pre class="r"><code># Checks for Normal/Symmetric distributions
p1 &lt;- ggplot(gpa_study_hours) + geom_histogram(aes(gpa))
p2 &lt;- ggplot(gpa_study_hours) + geom_histogram(aes(study_hours))
p3 &lt;- ggplot(gpa_study_hours) + geom_point(aes(gpa, study_hours))
(p1 + p2) / p3</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Pearson_example_1-1.png" width="672" /></p>
<p>Hmm…not normally distributed, and the relationship is also not linear,
and there is some evidence of heterscedasticity, so Pearson correlation
would not be the best idea here.</p>
<pre class="r"><code># Pearson Correlation as Linear Model
lm(gpa ~ study_hours, data = gpa_study_hours) %&gt;% summary()</code></pre>
<pre><code>## 
## Call:
## lm(formula = gpa ~ study_hours, data = gpa_study_hours)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.95130 -0.19456  0.03879  0.21708  0.73872 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 3.527997   0.037424  94.272   &lt;2e-16 ***
## study_hours 0.003328   0.001794   1.855   0.0652 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2837 on 191 degrees of freedom
## Multiple R-squared:  0.01769,	Adjusted R-squared:  0.01255 
## F-statistic:  3.44 on 1 and 191 DF,  p-value: 0.06517</code></pre>
<pre class="r"><code># Other ways using other packages
mosaic::cor_test(gpa ~ study_hours, data = gpa_study_hours)</code></pre>
<pre><code>## 
## 	Pearson&#39;s product-moment correlation
## 
## data:  gpa and study_hours
## t = 1.8548, df = 191, p-value = 0.06517
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.008383868  0.269196552
## sample estimates:
##       cor 
## 0.1330138</code></pre>
<pre class="r"><code>statsExpressions::corr_test(data = gpa_study_hours, 
                            x = study_hours, 
                            y = gpa)</code></pre>
<pre><code>## # A tibble: 1 × 14
##   parameter1  parameter2 effectsize          estimate conf.level conf.low
##   &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;
## 1 study_hours gpa        Pearson correlation    0.133       0.95 -0.00838
##   conf.high statistic df.error p.value method              n.obs conf.method
##       &lt;dbl&gt;     &lt;dbl&gt;    &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               &lt;int&gt; &lt;chr&gt;      
## 1     0.269      1.85      191  0.0652 Pearson correlation   193 normal     
##   expression
##   &lt;list&gt;    
## 1 &lt;language&gt;</code></pre>
<p>The correlation estimate is <span class="math inline">\(0.133\)</span>; the <code>p-value</code> is 0.065 and the
confidence interval includes 0. Hence we fail to reject the NULL
hypothesis that <code>study_hours</code> and <code>gpa</code> have no relationship.</p>
<p>We can use a later package <code>ggstaplot</code> to plot this:</p>
<pre class="r"><code>ggstatsplot::ggscatterstats(data = gpa_study_hours, 
                            x = study_hours, 
                            y = gpa,
                            type = &quot;robust&quot;,
                            marginal = TRUE,
                            title = &quot;GPA vs Study Hours&quot;)</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;ggside&#39;:
##   method from   
##   +.gg   ggplot2</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Pearson_example_3-1.png" width="672" /></p>
</div>
</div>
<div id="spearman-correlation" class="section level2 tabset">
<h2>Spearman Correlation</h2>
<div id="model-2" class="section level3">
<h3>Model</h3>
<p>In some cases the <strong>LINE</strong> assumptions may not hold. Nonlinear
relationships, non-normally distributed data ( with large outliers ) and
working with <em>ordinal</em> rather than continuous data: these situations
necessitate the use of Spearman’s <em>ranked</em> correlation scores.
(<strong>Ranked</strong>, not <strong>sign-ranked</strong>.)</p>
<p><span class="math display">\[
rank(y) = \beta_0 + \beta_1 * rank(x) \\
H_0: \beta_1 = 0
\]</span></p>
<p>Spearman correlation = Pearson correlation using the rank of the data
observations. Let’s check how this holds for a our x and y data:</p>
<pre class="r"><code># Plot the data
p1 &lt;- ggplot(mydata_wide, aes(x, y)) + 
  geom_point() +
  geom_smooth(method = &quot;lm&quot;) +
  ggtitle(&quot; Pearson Correlation\n and Linear Models&quot;)

# Plot ranked data
p2 &lt;- mydata_wide %&gt;% 
  mutate(x_rank = rank(x),
         y_rank = rank(y)) %&gt;%
  ggplot(.,aes(x_rank, y_rank)) + 
  geom_point(shape = 15, size = 2) +
  geom_smooth(method = &quot;lm&quot;) + 
  ggtitle(&quot; Spearman Ranked Correlation\n and Linear Models&quot;)

patchwork::wrap_plots(p1,p2, nrow = 1, guides = &quot;collect&quot;)</code></pre>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;
## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Spearman_Plot-1.png" width="672" /></p>
<p>Slopes are almost identical, ~ 0.25.</p>
</div>
<div id="code-2" class="section level3">
<h3>Code</h3>
<pre class="r"><code># Spearman
cor1 &lt;- cor.test(y,x, method = &quot;spearman&quot;) %&gt;% 
  broom::tidy() %&gt;% select(estimate, p.value)

# Pearson using ranks
cor2 &lt;- cor.test(rank(y), rank(x), method = &quot;pearson&quot;) %&gt;% 
broom::tidy() %&gt;% select(estimate, p.value)

# Linear Models using rank
cor3 &lt;- lm(rank(y) ~ 1 + rank(x),data = mydata_wide) %&gt;% 
  broom::tidy() %&gt;% select(estimate, p.value)

rbind(cor1, cor2, cor3) %&gt;% print()</code></pre>
<pre><code>## # A tibble: 4 × 2
##   estimate  p.value
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1   -0.227 1.13e- 1
## 2   -0.227 1.14e- 1
## 3   31.3   9.11e-10
## 4   -0.227 1.14e- 1</code></pre>
<p>Notes:</p>
<ol style="list-style-type: decimal">
<li><p>When ranks are used, the slope of the linear model (<span class="math inline">\(\beta_1\)</span>) has
the same value as the correlation coefficient ( <span class="math inline">\(\rho\)</span> ).</p></li>
<li><p>Note that the slope from the linear model now has an intuitive
interpretation: <strong>the number of ranks y changes for each change in
rank of x</strong>. ( Ranks are “independent” of <code>sd</code> )</p></li>
</ol>
</div>
<div id="example-2" class="section level3">
<h3>Example</h3>
<p>We examine the <code>cars93</code> data, where the numeric variables of interest
are <code>weight</code> and <code>price</code>.</p>
<pre class="r"><code>cars93 %&gt;% 
  ggplot(aes(weight, price)) + 
  geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE, lty = 2) + 
  labs(title = &quot;Car Weight and Car Price have a nonlinear relationship&quot;)</code></pre>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Spearman_example_1-1.png" width="672" /></p>
<p>Let us try a Spearman Correlation score for these variables, since the
data are not linearly related and the variance of <code>price</code> also is not
constant over <code>weight</code></p>
<pre class="r"><code>cor.test(cars93$price, cars93$weight, method = &quot;spearman&quot;) %&gt;% broom::tidy()</code></pre>
<pre><code>## Warning in cor.test.default(x, y, ...): Cannot compute exact p-value with ties</code></pre>
<pre><code>## # A tibble: 1 × 5
##   estimate statistic  p.value method                          alternative
##      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;                           &lt;chr&gt;      
## 1    0.883     3074. 1.07e-18 Spearman&#39;s rank correlation rho two.sided</code></pre>
<pre class="r"><code># Using linear Model
lm(rank(price) ~ rank(weight), data = cars93) %&gt;% summary()</code></pre>
<pre><code>## 
## Call:
## lm(formula = rank(price) ~ rank(weight), data = cars93)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -20.0676  -3.0135   0.7815   3.6926  20.4099 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   3.22074    2.05894   1.564    0.124    
## rank(weight)  0.88288    0.06514  13.554   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.46 on 52 degrees of freedom
## Multiple R-squared:  0.7794,	Adjusted R-squared:  0.7751 
## F-statistic: 183.7 on 1 and 52 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># Stats Plot
ggstatsplot::ggscatterstats(data = cars93, x = weight, 
                            y = price,
                            type = &quot;nonparametric&quot;,
                            title = &quot;Cars93: Weight vs Price&quot;,
                            subtitle = &quot;Spearman Correlation&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Spearman_example_2-1.png" width="672" /></p>
<p>We see that using ranks of the <code>price</code> variable, we obtain a Spearman’s
<span class="math inline">\(\rho = 0.882\)</span> with a <code>p-value</code> that is very small. Hence we are able to
reject the NULL hypothesis and state that there is a relationship
between these two variables. The <strong>linear</strong> relationship is evaluated as
a correlation of <code>0.882</code>.</p>
</div>
</div>
</div>
<div id="tests-on-one-mean" class="section level1 tabset">
<h1>Tests on One Mean</h1>
<p>A series of tests deal with one mean value of a sample. The idea is to
evaluate whether that mean is representative of the mean of the
underlying population.</p>
<p>This uses the <em>Student’s t-test</em> for parametric data and the <em>Wilcoxon
signed-rank test</em> for non-parametric data.</p>
<p>Tests can involve a <em>single sample</em> or <em>paired samples</em>.</p>
<div id="the-students-t-test-with-one-sample" class="section level2 tabset">
<h2>The Student’s t-test with one sample</h2>
<div id="model-3" class="section level3">
<h3>Model</h3>
<p>A single number predicts y:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1*x \\
\\and\ further \ actually\\
y = \beta_0
\]</span></p>
<p>and the second term vanishes, since “there is no x”: all the x-values
are made equal to zero in the linear model !! The NULL Hypothesis
therefore is:</p>
<p><span class="math display">\[
\ H_0: \beta_0 = 0
\]</span></p>
<p>This NULL Hypothesis makes sense, because in the accompanying linear
model all values of the <u>explanatory</u> variable x are zero, and
therefore the NULL Hypothesis for the model should be that y also should
be zero mean. Note that if we <strong>want</strong> the NULL hypothesis to be that
the mean is other than zero, we can use the
<code>lm(...., mu = some_number, ..)</code> parameter in the command.</p>
</div>
<div id="code-3" class="section level3">
<h3>Code</h3>
<p>If we compare the <code>t.test</code> with the appropriate <code>lm</code> model:</p>
<pre class="r"><code># t-test
t1 &lt;- t.test(y, mu = 0, alternative = &quot;two.sided&quot;)
print(t1)</code></pre>
<pre><code>## 
## 	One Sample t-test
## 
## data:  y
## t = 1.0607, df = 49, p-value = 0.294
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -0.2683937  0.8683937
## sample estimates:
## mean of x 
##       0.3</code></pre>
<pre class="r"><code># linear model
lm1 &lt;- lm(y ~ 1, data = mydata_wide)
lm1 %&gt;% summary()</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ 1, data = mydata_wide)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5554 -1.4845 -0.0392  1.5559  4.5119 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.3000     0.2828   1.061    0.294
## 
## Residual standard error: 2 on 49 degrees of freedom</code></pre>
<pre class="r"><code>lm1 %&gt;% confint()</code></pre>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -0.2683937 0.8683937</code></pre>
<p>The confidence intervals for both the <code>t.test</code> and the <code>lm</code> model are
identical.</p>
<p>t-test confidence intervals: -0.2683937, 0.8683937<br />
linear model confidence intervals: -0.2683937, 0.8683937</p>
<p>So even though y has a mean of 0.3, the confidence intervals straddle
zero, and hence we cannot reject the NULL hypothesis that the true
population, of which y is a sample, could have mean=0.</p>
</div>
<div id="example-3" class="section level3">
<h3>Example</h3>
<pre class="r"><code>exam_grades</code></pre>
<pre><code>## # A tibble: 233 × 6
##    semester sex   exam1 exam2 exam3 course_grade
##    &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;
##  1 2000-1   Man    84.5  69.5  86.5         76.3
##  2 2000-1   Man    80    74    67           75.4
##  3 2000-1   Man    56    70    71.5         67.1
##  4 2000-1   Man    64    61    67.5         63.5
##  5 2000-1   Man    90.5  72.5  75           72.4
##  6 2000-1   Man    74    78.5  84.5         71.4
##  7 2000-1   Man    60.5  44    58           56.1
##  8 2000-1   Man    89    82    88           78.0
##  9 2000-1   Woman  87.5  86.5  95           82.9
## 10 2000-1   Man    91    98    88           89.1
## # … with 223 more rows</code></pre>
</div>
</div>
<div id="wilcoxons-signed-rank-test" class="section level2 tabset">
<h2>Wilcoxon’s Signed-Rank Test</h2>
<p>Since we are dealing with the <strong>mean</strong>, the <em>sign</em> of the rank becomes
important to use, in the case of a non-parametric single mean test.</p>
<div id="model-4" class="section level3">
<h3>Model</h3>
<p><span class="math display">\[
signed\_rank(y) = \beta_0 \\
H_0: \beta_0 = 0
\]</span></p>
</div>
<div id="code-4" class="section level3">
<h3>Code</h3>
<pre class="r"><code># Standard Wilcoxon Signed_Rank Test
w1 &lt;- wilcox.test(y)
w1</code></pre>
<pre><code>## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  y
## V = 754, p-value = 0.2628
## alternative hypothesis: true location is not equal to 0</code></pre>
<pre class="r"><code># Wilcoxon test with lm
w2 &lt;- lm(signed_rank(y) ~ 1 , data = mydata_wide)
w2</code></pre>
<pre><code>## 
## Call:
## lm(formula = signed_rank(y) ~ 1, data = mydata_wide)
## 
## Coefficients:
## (Intercept)  
##        4.66</code></pre>
<pre class="r"><code># t-test with signed_rank data
w3 &lt;- t.test(signed_rank(y))
w3</code></pre>
<pre><code>## 
## 	One Sample t-test
## 
## data:  signed_rank(y)
## t = 1.1277, df = 49, p-value = 0.265
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -3.644491 12.964491
## sample estimates:
## mean of x 
##      4.66</code></pre>
<p>We can plot the y data both original and ranked to see where the mean
lies in each case. The approximation to the true $_0 ( is good
when the number of observations N is &gt;=50. Lindoloev has a <a href="https://lindeloev.github.io/tests-as-linear/simulations/simulate_wilcoxon.html">simulation
on
this.</a>.
We can also plot the model using <em>lm</em> for both the original data and the
sign-ranked data.</p>
</div>
<div id="example-4" class="section level3">
<h3>Example</h3>
</div>
<div id="plots-for-both-t-test-and-wilcoxon-test" class="section level3">
<h3>Plots for both t-test and Wilcoxon test</h3>
<pre class="r"><code>p1 &lt;- ggplot(mydata_wide, aes( x = 0, y = y)) +
  geom_point(alpha = 0.4) +
  geom_segment(aes(y = t1$estimate, 
                   yend = t1$estimate, 
                   x = -0.2, xend = 0.2)) + 
  labs(title = &quot;Student&#39;s\n t-Test&quot;)

# t-test using linear model
p2 &lt;- ggplot(mydata_wide, aes( x = 0, y = y)) +
  geom_point(alpha = 0.4) +
  geom_segment(aes(y = lm(y ~ 1)$coefficient, 
                   yend = lm(y ~ 1)$coefficient, 
                   x = -0.2, xend = 0.2)) + 
  labs(title = &quot;Student&#39;s\n t-Test \n using lm&quot;)

# Wilcoxon test, using signed-ranks of data
p3 &lt;- ggplot(mydata_wide, aes( x = 0, y = signed_rank(y))) +
  geom_point(alpha = 0.4) +
  geom_segment(aes(y = mean(signed_rank(y)), yend = mean(signed_rank(y)), x = -0.2, xend = 0.2)) + 
  labs(title = &quot;Wilcoxon \nSigned-Rank\n Test&quot;)

# Wilcoxon test, using signed-ranks of data, and lm
p4 &lt;- ggplot(mydata_wide, aes( x = 0, y = signed_rank(y))) +
  geom_point(alpha = 0.4) +
  geom_segment(aes(y = lm(signed_rank(y) ~1)$coefficient, 
                   yend = lm(signed_rank(y) ~1)$coefficient, 
                   x = -0.2, xend = 0.2)) + 
  labs(title = &quot;Wilcoxon \n Signed-Rank \n Test with lm&quot;)


patchwork::wrap_plots(p1,p2,p3,p4, nrow = 1, guides = &quot;collect&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Mean_Related_Plots-1.png" width="672" /></p>
</div>
</div>
<div id="paired-sample-t-test" class="section level2 tabset">
<h2>Paired Sample t-test</h2>
<p>We use this when we have two samples and the observations from one
sample can be “paired” with observations in the other sample. Controlled
studies for interventions/measures, such as before/after kind of data,
comparisons between two interventions on the same set of subjects, and
two measurements made on the same subjects using different methods etc.</p>
<div id="model-5" class="section level3">
<h3>Model</h3>
<p><span class="math display">\[
y_2 - y_1 = \beta_0 \\
H_0 : \beta_0 = 0
\]</span></p>
<p>The NULL Hypothesis is that there is no difference, <strong>either way</strong>,
between the two samples. Again, in the linear model, we assume as before
that “the explanatory x variable has been equated to zero.</p>
<p>We therefore set <code>two.sided</code> and <code>mu = 0</code> in the <code>t.test</code>.</p>
</div>
<div id="code-5" class="section level3">
<h3>Code</h3>
<pre class="r"><code># Using paired t-test
t2 &lt;- t.test(y2, y, paired = TRUE, mu = 0, 
             alternative = &quot;two.sided&quot;)
t2</code></pre>
<pre><code>## 
## 	Paired t-test
## 
## data:  y2 and y
## t = 0.54264, df = 49, p-value = 0.5898
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##  -0.54067  0.94067
## sample estimates:
## mean difference 
##             0.2</code></pre>
<pre class="r"><code># linear model
lm2 &lt;- lm(y2-y ~ 1, data = mydata_wide)
lm2 %&gt;% summary()</code></pre>
<pre><code>## 
## Call:
## lm(formula = y2 - y ~ 1, data = mydata_wide)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.7027 -2.1872 -0.1367  1.3835  5.7262 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.2000     0.3686   0.543     0.59
## 
## Residual standard error: 2.606 on 49 degrees of freedom</code></pre>
<pre class="r"><code>lm2 %&gt;% confint()</code></pre>
<pre><code>##                2.5 %  97.5 %
## (Intercept) -0.54067 0.94067</code></pre>
<p>Both tests report the difference to be 0.2. However the p-value in both
tests is about 0.6, so the result is not statistically significant.</p>
</div>
<div id="example-5" class="section level3">
<h3>Example</h3>
</div>
</div>
<div id="wilcoxon-paired-test" class="section level2 tabset">
<h2>Wilcoxon Paired Test</h2>
<p>When the original data is not normally distributed or has outliers etc,.
we use a nonparametric Wilcoxon paired test. The difference between the
paired and unpaired Wilcoxon test is that the test is run on the
signed-ranks of the <strong>pairwise differences</strong> y2- y.</p>
<div id="model-6" class="section level3">
<h3>Model</h3>
<p>$$ signed_rank(y2 - y1) = _0 \</p>
<p>H_0: _0 = 0</p>
<p>$$</p>
</div>
<div id="code-6" class="section level3">
<h3>Code</h3>
<pre class="r"><code># Paired Wilcoxon Test
w4 &lt;- wilcox.test(y, y2, paired = TRUE)
w4</code></pre>
<pre><code>## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  y and y2
## V = 608, p-value = 0.7795
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<pre class="r"><code># Linear Model
lm4 &lt;- lm(signed_rank(y2-y) ~ 1 , data = mydata_wide)
lm4 %&gt;% summary()</code></pre>
<pre><code>## 
## Call:
## lm(formula = signed_rank(y2 - y) ~ 1, data = mydata_wide)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -48.18 -27.93   0.82  22.57  48.82 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)    1.180      4.182   0.282    0.779
## 
## Residual standard error: 29.57 on 49 degrees of freedom</code></pre>
<pre class="r"><code># t-test with Signed Rank
t4 &lt;- t.test(signed_rank(y2-y), mu = 0 , alternative = &quot;two.sided&quot;)
t4</code></pre>
<pre><code>## 
## 	One Sample t-test
## 
## data:  signed_rank(y2 - y)
## t = 0.28214, df = 49, p-value = 0.779
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -7.224733  9.584733
## sample estimates:
## mean of x 
##      1.18</code></pre>
<p>Here too, the p-values reported by the three tests are p = 0.779 so the
difference reported is not significant.</p>
</div>
<div id="example-6" class="section level3">
<h3>Example</h3>
</div>
</div>
</div>
<div id="tests-with-two-means" class="section level1 tabset">
<h1>Tests with Two Means</h1>
<p>When we have two independent samples and these are <em>not paired</em> as
earlier. The intent is to test if there is a significant difference to
their means. An example is identical measurements on two sets of
subjects.</p>
<p>There is considerable discussion on what test to use when: 1.If
variances are equal between samples, observations are normally
distributed within groups, no outliers, then <code>independent t-test</code> 2. If
unequal variance, <code>t-test</code> with <code>Welch correction</code> ( Welch’s t-test) 3.
If samples are not normal, then nonparametric test ( Wilcoxon with two
samples = <code>Mann-Whitney test</code>). Symmetry of the distribution is assumed
here.</p>
<div id="dummy-group-variable-concept" class="section level2">
<h2>Dummy Group Variable Concept</h2>
<p>An important construct here is the <strong>dummy variable</strong>. When there is
more than one group in the data, a dummy <em>categorical variable</em> is set
up, whose entries specify the group ID. The group IDs are <strong>still
numerical</strong> ( as with factors, remember ). The dummy variable is plotted
on the x-axis. The consecutive IDs in the dummy variable x are separated
by <em>1</em>. Hence the <em>between-groups difference</em> in the stat measures
computed on y are numerically equivalent to the <strong>slope</strong> in the linear
model. Thus the <em>dummy variable</em> allows us to **mathematically* use
the linear model, as presented in the equations above.</p>
<p>Dummy variables become even more useful when the explanatory variable (
“x-planatory” ) is already categorical, as with ANOVA and friends.</p>
<p>We can visualize this as follows:</p>
<pre class="r"><code>mydata_wide_new &lt;- 
  tibble(y1 = rnorm(50, mean = 0, sd = 0.5),
         y2 = rnorm(50, mean = 1.2, sd = 0.5)) %&gt;%
  pivot_longer(cols = c(y1, y2),
               names_to = &quot;variable&quot;,  
               values_to = &quot;values&quot;) %&gt;% 
  cbind(group = rep(0:1, 50))

mydata_wide_new %&gt;% 
  ggplot(aes(x = group, y = values)) + 
  geom_point() + 
  stat_summary(fun = &quot;mean&quot;, colour = &quot;red&quot;, size = 4, geom =&quot;point&quot;) +
  stat_summary(fun = &quot;mean&quot;, geom= &quot;line&quot;, colour = &quot;blue&quot;, lty = 2) +
  xlab(&quot;Dummy Variable to show groups&quot;) +
  ylab(&quot;y1 and y2, on the same scale&quot;) +
  scale_x_discrete(name = &quot;Dummy Variable x_i  [0,1]&quot;,
                limits = c(0,1)) +
  annotate(&quot;text&quot;, x = 0, y = 1.5, label = &quot;Difference in means \n equals slope in linear model&quot;) </code></pre>
<pre><code>## Warning: Continuous limits supplied to discrete scale.
## ℹ Did you mean `limits = factor(...)` or `scale_*_continuous()`?</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Independent_Data_Plots-1.png" width="672" /></p>
<pre class="r"><code># Need to use `glue` here to add more annotations
# Math annotation on graphs</code></pre>
</div>
<div id="model-7" class="section level2">
<h2>Model</h2>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 * x_i \\
where\\
x_i= \left\{\begin{matrix}
1\ when\ x\ \in\ Group 1\\
0\ when\ x\ \in\ Group2
\end{matrix}\right.
\]</span></p>
</div>
</div>
<div id="section" class="section level1 unnumbered">
<h1 class="unnumbered"></h1>
<p>Let us now look at the tests.</p>
<div id="independent-t-test" class="section level2 tabset">
<h2>Independent t-test</h2>
<div id="model-8" class="section level3">
<h3>Model</h3>
<p>The assumptions here are: - both data sets are normally distributed.
Small samples may be assumned to be <code>t-distributed</code> - variances are the
same - no outliers - observations across data sets are independent
(obviously)</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 * x_i \\
where \\
x_i= \left\{\begin{matrix}
1\ when\ x\ \in\ Group 1\\
0\ when\ x\ \in\ Group2
\end{matrix}\right.
\\
H_0 : \beta_1 = 0
\]</span></p>
<p>The t.test computes a statistic as follows:</p>
<p><span class="math display">\[
t \ \ = \mod(\bar{x_1}\ - \bar{x_2}) / std.error(\bar{x_1}\ - \bar{x_2}) \\
= \mod(\bar{x_1} - \bar{x_2})\ / \sqrt{s_x^2 /n_x + s_y^2/n_y}  \\
and\\
df = n_1 + n_2 - 2\ \ \ \ ( degrees\ of\ freedom)
\]</span></p>
<p>The t-test uses an approximation to the sampling distribution of the
difference in sample means based on the Central Limit Theorem, which
ensures that for sufficiently large samples, the sampling distribution
will be very close to Normal. The mean of the sampling distribution will
be the difference in (underlying) population means, and the variance of
the sampling distribution will be the standard error of the difference
in sample means.</p>
<p>For the <code>t-statistic</code>, note that the numerator of the formula is the
difference between means. The denominator is a measurement of
experimental error in the two groups combined. The wider the difference
between means, the more confident you are in the data. The more
experimental error you have, the less confident you are in the data.
Thus the higher the value of t, the greater the confidence that there is
a difference.</p>
<p>The <code>t-statistic</code> has a t-distribution. It is compared to a <em>critical
value</em> of t, for a given probability value ( 0.05 usually). If the
calculated t exceeds the critical value, we can assert that the NULL
Hypothesis can be rejected and there could be a significant difference
in means. <img src="t-distribution.png" alt="t-distribution curves" /></p>
</div>
<div id="code-7" class="section level3">
<h3>Code</h3>
<pre class="r"><code># Independent t-test
t5 &lt;- t.test(y2, y, var.equal = TRUE)
t5 %&gt;% tidy() </code></pre>
<pre><code>## # A tibble: 1 × 10
##   estim…¹ estim…² estim…³ stati…⁴ p.value param…⁵ conf.…⁶ conf.…⁷ method alter…⁸
##     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  
## 1     0.2     0.5     0.3   0.566   0.573      98  -0.502   0.902 Two S… two.si…
## # … with abbreviated variable names ¹​estimate, ²​estimate1, ³​estimate2,
## #   ⁴​statistic, ⁵​parameter, ⁶​conf.low, ⁷​conf.high, ⁸​alternative</code></pre>
<pre class="r"><code># Welch test when variances are not equal
t6 &lt;- t.test(y2,y, var.equal = FALSE)
t6 %&gt;% tidy()</code></pre>
<pre><code>## # A tibble: 1 × 10
##   estim…¹ estim…² estim…³ stati…⁴ p.value param…⁵ conf.…⁶ conf.…⁷ method alter…⁸
##     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  
## 1     0.2     0.5     0.3   0.566   0.573    90.9  -0.502   0.902 Welch… two.si…
## # … with abbreviated variable names ¹​estimate, ²​estimate1, ³​estimate2,
## #   ⁴​statistic, ⁵​parameter, ⁶​conf.low, ⁷​conf.high, ⁸​alternative</code></pre>
<pre class="r"><code># Linear Model with Dummy variable
# lm(value ~ 1 + group, data = mydata_long_y) # also works
lm6 &lt;- lm(value ~ 1 + I(group == &quot;y2&quot;), data = mydata_long_y)
lm6 %&gt;% tidy()</code></pre>
<pre><code>## # A tibble: 2 × 5
##   term                     estimate std.error statistic p.value
##   &lt;chr&gt;                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 &quot;(Intercept)&quot;                 0.3     0.25      1.2     0.233
## 2 &quot;I(group == \&quot;y2\&quot;)TRUE&quot;      0.2     0.354     0.566   0.573</code></pre>
<p>We get the same estimates for means of y and y2 ( 0.3 and 0.5
respectively).</p>
</div>
<div id="example-7" class="section level3">
<h3>Example</h3>
</div>
</div>
<div id="welchs-t-test" class="section level2 tabset">
<h2>Welch’s t-test</h2>
<div id="model-9" class="section level3">
<h3>Model</h3>
<p>Welch’s test we have already explored as a variant of the t.test for two
means, with variances unequal.</p>
<p>Welch’s test is also stated as a <em>Generalized</em> Linear Model using, not
<code>lm</code> but the <code>gls</code> command from the <code>nlme</code> package. This is explained on
<a href="https://stats.stackexchange.com/questions/142685/equivalent-to-welchs-t-test-in-gls-framework">StackExchange</a>
but we need not digress now.</p>
<p>When the variances are unequal, there is a difference in the t-statistic
that is computed <em>only</em> when the group **sizes* are different (
Denominator of t-statistic ).</p>
<p>From StackExchange:<br />
<span class="math display">\[
t_w =\ \frac {\bar{x_1}-\bar{x_2}}{\sqrt{{s_1^2/n_1}{s_2^2/n_2}}}
\\\\
=\ \frac{\bar{x_1}-\bar{x_2}} {{\sqrt{\frac{s_1^2 + s_2^2}{n}}}}
\\\\
=\ \frac{\bar{x_1}-\bar{x_2}} {{\sqrt{\frac{s_1^2 + s_2^2} {2} * (\frac{2}{n})}}}
\\\\
=\ t_s
\]</span></p>
<p>So under these conditions the t-statistic for the Welch t-test is the
same as that for the standard t-test.</p>
</div>
<div id="code-8" class="section level3">
<h3>Code</h3>
<pre class="r"><code>t7 &lt;- t.test(y, y2, var.equal = FALSE)</code></pre>
</div>
<div id="example-8" class="section level3">
<h3>Example</h3>
</div>
</div>
<div id="mann-whitney-u-test" class="section level2 tabset">
<h2>Mann-Whitney U Test</h2>
<p>(Wilcoxon Independent Sample test)</p>
<p>As before, when sample groups are not normally distributed, and when
variances are different, and they are outliers, a nonparametric rank-sum
test is preferred. This is the same as the Wilcoxon Test for independent
variables, and is called the Mann-Whitney Test.</p>
<div id="model-10" class="section level3">
<h3>Model</h3>
<p>As before:</p>
<p><span class="math display">\[
rank(y_i) = \beta_0 + \beta_1 * rank(x_i) \\
where \\
x_i= \left\{\begin{matrix}
1\ when\ x\ \in\ Group 1\\
0\ when\ x\ \in\ Group2
\end{matrix}\right.
\\
H_0 : \beta_1 = 0
\]</span></p>
</div>
<div id="code-9" class="section level3">
<h3>Code</h3>
<pre class="r"><code># As Wilcoxon Test
w5 &lt;- wilcox.test(y2,y, paired = FALSE)
w5 %&gt;% tidy()</code></pre>
<pre><code>## # A tibble: 1 × 4
##   statistic p.value method                                            alternat…¹
##       &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                                             &lt;chr&gt;     
## 1      1264   0.926 Wilcoxon rank sum test with continuity correction two.sided 
## # … with abbreviated variable name ¹​alternative</code></pre>
<pre class="r"><code># As Linear model
lm5 &lt;- lm(rank(value) ~ 1 + I(group == &quot;y2&quot;), 
          data = mydata_long_y)
lm5 %&gt;% tidy()</code></pre>
<pre><code>## # A tibble: 2 × 5
##   term                     estimate std.error statistic  p.value
##   &lt;chr&gt;                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 &quot;(Intercept)&quot;              50.2        4.12   12.2    2.50e-21
## 2 &quot;I(group == \&quot;y2\&quot;)TRUE&quot;    0.560      5.83    0.0960 9.24e- 1</code></pre>
<p>Not clear how to explain this. Need to dig more into Mann-Whitney.</p>
</div>
<div id="example-9" class="section level3">
<h3>Example</h3>
</div>
</div>
</div>
<div id="tests-with-three-or-more-means" class="section level1 tabset">
<h1>Tests with Three or More Means</h1>
<div id="model-11" class="section level2">
<h2>Model</h2>
<p>ANOVAs are linear models with (only) categorical predictors so they
simply extend everything we did above, relying heavily on dummy coding.</p>
</div>
<div id="one-way-anova" class="section level2 tabset">
<h2>One-way ANOVA</h2>
<div id="model-12" class="section level3">
<h3>Model</h3>
<p>One mean for each group predicts y.</p>
<p><span class="math display">\[
y=\beta_0 + \beta_1*x_1 + \beta_2*x_2...+\beta_n*x_n\\
H0:y=β0
\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> are indicators (x=0 or x=1) where at most one <span class="math inline">\(x_i=1\)</span> while
all others are <span class="math inline">\(x_i=0\)</span>.</p>
<p>Notice how this is just “more of the same” of what we already did in
other models above. When there are only two groups, this model is
<span class="math inline">\(y=β0+β1∗x\)</span>, i.e. the <em>independent t-test</em>. If there is only one group,
it is <span class="math inline">\(y=β0\)</span>, i.e. the <em>one-sample t-test</em>. This makes <em>one-way ANOVA</em> a
<strong>multiple regression</strong> model.</p>
<p>This is easy to see in the visualization below - just cover up a few
groups and see that it matches the other visualizations above. Let’s
visualize this using toy data:</p>
<pre class="r"><code>N = 15
D_anova1 = data.frame(
  y = c(
    rnorm_fixed(N, 0.5, 0.3),
    rnorm_fixed(N, 0, 0.3),
    rnorm_fixed(N, 1, 0.3),
    rnorm_fixed(N, 0.8, 0.3)
  ),
  x = rep(0:3, each = 15)
)
ymeans = aggregate(y~x, D_anova1, mean)$y
P_anova1 = ggplot(D_anova1, aes(x=x, y=y)) + 
  stat_summary(fun.y=mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y.., color=&#39;intercepts&#39;), lwd=2) + 
  
  geom_segment(x = -10, xend = 100, 
               y = 0.5, yend = 0.5, 
               lwd = 2, aes(color = &#39;beta_0&#39;)) +
  geom_segment(x = 0, xend = 1, 
               y = ymeans[1], yend = ymeans[2], 
               lwd = 2, aes(color = &#39;betas&#39;)) +
  geom_segment(x = 1, xend = 2, 
               y = ymeans[1], yend = ymeans[3], 
               lwd = 2, aes(color = &#39;betas&#39;)) +
  geom_segment(x = 2, xend = 3, 
               y = ymeans[1], yend = ymeans[4], 
               lwd = 2, aes(color = &#39;betas&#39;)) +
  
  scale_color_manual(name = NULL, 
                     values = c(&quot;blue&quot;, &quot;red&quot;, &quot;darkblue&quot;),
                     labels=c(bquote(beta[0]*&quot; (group 1 mean)&quot;),
                              bquote(beta[1]*&quot;, &quot;*beta[2]*&quot;, 
                                     etc. (slopes/differences to &quot;*beta[0]*&quot;)&quot;),
      bquote(beta[0]*&quot;+&quot;*beta[1]*&quot;, &quot;*beta[0]*&quot;+&quot;*beta[2]*&quot;, etc. (group 2, 3, ... means)&quot;)
    )
  )</code></pre>
<pre><code>## Warning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.
## ℹ Please use the `fun` argument instead.</code></pre>
<pre><code>## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## ℹ Please use `linewidth` instead.</code></pre>
<pre class="r"><code>P_anova1</code></pre>
<pre><code>## Warning: The dot-dot notation (`..y..`) was deprecated in ggplot2 3.4.0.
## ℹ Please use `after_stat(y)` instead.</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Visualizing_One_way_ANOVA-1.png" width="672" /></p>
</div>
<div id="code-10" class="section level3">
<h3>Code</h3>
</div>
<div id="example-10" class="section level3">
<h3>Example</h3>
</div>
</div>
<div id="two-way-anova" class="section level2 tabset">
<h2>Two-way ANOVA</h2>
<div id="model-13" class="section level3">
<h3>Model</h3>
</div>
<div id="code-11" class="section level3">
<h3>Code</h3>
</div>
<div id="example-11" class="section level3">
<h3>Example</h3>
</div>
</div>
<div id="ancova" class="section level2 tabset">
<h2>ANCOVA</h2>
<div id="model-14" class="section level3">
<h3>Model</h3>
</div>
<div id="code-12" class="section level3">
<h3>Code</h3>
</div>
<div id="example-12" class="section level3">
<h3>Example</h3>
</div>
</div>
</div>
<div id="proportions" class="section level1 tabset">
<h1>Proportions</h1>
<div id="model-15" class="section level2">
<h2>Model</h2>
</div>
<div id="discrete-variables" class="section level2 tabset">
<h2>Discrete Variables</h2>
<div id="model-16" class="section level3">
<h3>Model</h3>
</div>
<div id="code-13" class="section level3">
<h3>Code</h3>
</div>
<div id="example-13" class="section level3">
<h3>Example</h3>
</div>
</div>
<div id="continuous-variables" class="section level2 tabset">
<h2>Continuous Variables</h2>
<div id="model-17" class="section level3">
<h3>Model</h3>
</div>
<div id="code-14" class="section level3">
<h3>Code</h3>
</div>
<div id="example-14" class="section level3">
<h3>Example</h3>
</div>
</div>
</div>
