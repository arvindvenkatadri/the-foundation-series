---
date: "2022-12-03"
title: "Samples, Populations, Statistics and Inference"
author: "Arvind Venkatadri"
external_link: ""
weight: 20
image:
  caption: Photo by <a href="https://unsplash.com/@lanirudhreddy?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">ANIRUDH</a> on <a href="https://unsplash.com/s/photos/matrix?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
  focal_point: Smart
links:
- icon: magic
  icon_pack: fas
  name: Slides
  url: 
- icon: flask
  icon_pack: fas
  name: Game
  url: 
- icon: file-powerpoint
  icon_pack: fa
  name: Case Study
  url: 
slides: 
summary: "How much Data does a Man need?"
tags:
- Models
- 
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""
---

<script src="{{< blogdown/postref >}}index_files/font-awesome/js/script.js"></script>


<div id="what-is-a-population" class="section level2">
<h2>What is a Population?</h2>
<p>A <em>population</em> is a collection of individuals or observations we are interested in. This is also commonly denoted as a study population. We mathematically denote the population’s size using upper-case <code>N</code>.</p>
<p>A <em>population parameter</em> is some numerical summary about the population that is unknown but you wish you knew. For example, when this quantity is a mean like the average height of all Bangaloreans, the population parameter of interest is the population mean.</p>
<p>A <em>census</em> is an exhaustive enumeration or counting of all N individuals in the population. We do this in order to compute the population parameter’s value exactly. Of note is that as the number N of individuals in our population increases, conducting a census gets more expensive (in terms of time, energy, and money).</p>
</div>
<div id="what-is-a-sample" class="section level2">
<h2>What is a Sample?</h2>
<p>Sampling is the act of collecting a sample from the population, which we generally do when we can’t perform a census. We mathematically denote the sample size using lower case <code>n</code>, as opposed to upper case N which denotes the population’s size. Typically the sample size n is much smaller than the population size N. Thus sampling is a much cheaper alternative than performing a census.</p>
<p>A <strong>sample statistic</strong>, also known as a <em>point estimate</em>, is a summary statistic like a mean or standard deviation that is computed from a sample.</p>
</div>
<div id="why-do-we-sample" class="section level2">
<h2>Why do we sample?</h2>
<p>Because we cannot conduct a census ( not always ) — and sometimes we won’t even know how big the population is — we take samples. And we <em>still</em> want to do useful work for/with the population, after <em>estimating its parameters, an act of generalizing</em> from sample to population. So the question is, <strong>can we estimate useful parameters of the population, using just samples? Can point estimates serve as useful guides to population parameters?</strong></p>
<p>This act of generalizing from sample to population is at the heart of <strong>statistical inference</strong>.</p>
<p>NOTE: there is an <em>alliterative mnemonic</em> here: <strong>S</strong>amples have <strong>S</strong>tatistics; <strong>P</strong>opulations have <strong>P</strong>arameters.</p>
</div>
<div id="sampling" class="section level2">
<h2>Sampling</h2>
<p>We will first execute some samples from a known dataset. We load up the NHANES dataset and inspect it.</p>
<pre class="r"><code>data(&quot;NHANES&quot;)
mosaic::inspect(NHANES)</code></pre>
<pre><code>## 
## categorical variables:  
##                name  class levels     n missing                                  distribution
## 1          SurveyYr factor      2 10000       0 2009_10 (50%), 2011_12 (50%)                 
## 2            Gender factor      2 10000       0 female (50.2%), male (49.8%)                 
## 3         AgeDecade factor      8  9667     333  40-49 (14.5%),  0-9 (14.4%) ...             
## 4             Race1 factor      5 10000       0 White (63.7%), Black (12%) ...               
## 5             Race3 factor      6  5000    5000 White (62.7%), Black (11.8%) ...             
## 6         Education factor      5  7221    2779 Some College (31.4%) ...                     
## 7     MaritalStatus factor      6  7231    2769 Married (54.6%), NeverMarried (19.1%) ...    
## 8          HHIncome factor     12  9189     811 more 99999 (24.2%) ...                       
## 9           HomeOwn factor      3  9937      63 Own (64.7%), Rent (33.1%) ...                
## 10             Work factor      3  7771    2229 Working (59.4%), NotWorking (36.6%) ...      
## 11 BMICatUnder20yrs factor      4  1274    8726 NormWeight (63.2%), Obese (17.3%) ...        
## 12          BMI_WHO factor      4  9603     397 18.5_to_24.9 (30.3%) ...                     
## 13         Diabetes factor      2  9858     142 No (92.3%), Yes (7.7%)                       
## 14        HealthGen factor      5  7539    2461 Good (39.2%), Vgood (33.3%) ...              
## 15   LittleInterest factor      3  6667    3333 None (76.5%), Several (16.9%) ...            
## 16        Depressed factor      3  6673    3327 None (78.6%), Several (15.1%) ...            
## 17     SleepTrouble factor      2  7772    2228 No (74.6%), Yes (25.4%)                      
## 18       PhysActive factor      2  8326    1674 Yes (55.8%), No (44.2%)                      
## 19         TVHrsDay factor      7  4859    5141 2_hr (26.2%), 1_hr (18.2%) ...               
## 20       CompHrsDay factor      7  4863    5137 0_to_1_hr (29%), 0_hrs (22.1%) ...           
## 21  Alcohol12PlusYr factor      2  6580    3420 Yes (79.2%), No (20.8%)                      
## 22         SmokeNow factor      2  3211    6789 No (54.3%), Yes (45.7%)                      
## 23         Smoke100 factor      2  7235    2765 No (55.6%), Yes (44.4%)                      
## 24        Smoke100n factor      2  7235    2765 Non-Smoker (55.6%), Smoker (44.4%)           
## 25        Marijuana factor      2  4941    5059 Yes (58.5%), No (41.5%)                      
## 26     RegularMarij factor      2  4941    5059 No (72.4%), Yes (27.6%)                      
## 27        HardDrugs factor      2  5765    4235 No (81.5%), Yes (18.5%)                      
## 28          SexEver factor      2  5767    4233 Yes (96.1%), No (3.9%)                       
## 29          SameSex factor      2  5768    4232 No (92.8%), Yes (7.2%)                       
## 30   SexOrientation factor      3  4842    5158 Heterosexual (95.8%), Bisexual (2.5%) ...    
## 31      PregnantNow factor      3  1696    8304 No (92.7%), Yes (4.2%) ...                   
## 
## quantitative variables:  
##               name   class      min        Q1    median        Q3        max         mean           sd     n missing
## 1               ID integer 51624.00 56904.500 62159.500 67039.000  71915.000 6.194464e+04 5.871167e+03 10000       0
## 2              Age integer     0.00    17.000    36.000    54.000     80.000 3.674210e+01 2.239757e+01 10000       0
## 3        AgeMonths integer     0.00   199.000   418.000   624.000    959.000 4.201239e+02 2.590431e+02  4962    5038
## 4      HHIncomeMid integer  2500.00 30000.000 50000.000 87500.000 100000.000 5.720617e+04 3.302028e+04  9189     811
## 5          Poverty numeric     0.00     1.240     2.700     4.710      5.000 2.801844e+00 1.677909e+00  9274     726
## 6        HomeRooms integer     1.00     5.000     6.000     8.000     13.000 6.248918e+00 2.277538e+00  9931      69
## 7           Weight numeric     2.80    56.100    72.700    88.900    230.700 7.098180e+01 2.912536e+01  9922      78
## 8           Length numeric    47.10    75.700    87.000    96.100    112.200 8.501602e+01 1.370503e+01   543    9457
## 9         HeadCirc numeric    34.20    39.575    41.450    42.925     45.400 4.118068e+01 2.311483e+00    88    9912
## 10          Height numeric    83.60   156.800   166.000   174.500    200.400 1.618778e+02 2.018657e+01  9647     353
## 11             BMI numeric    12.88    21.580    25.980    30.890     81.250 2.666014e+01 7.376579e+00  9634     366
## 12           Pulse integer    40.00    64.000    72.000    82.000    136.000 7.355973e+01 1.215542e+01  8563    1437
## 13        BPSysAve integer    76.00   106.000   116.000   127.000    226.000 1.181550e+02 1.724817e+01  8551    1449
## 14        BPDiaAve integer     0.00    61.000    69.000    76.000    116.000 6.748006e+01 1.435480e+01  8551    1449
## 15          BPSys1 integer    72.00   106.000   116.000   128.000    232.000 1.190902e+02 1.749636e+01  8237    1763
## 16          BPDia1 integer     0.00    62.000    70.000    76.000    118.000 6.827826e+01 1.378078e+01  8237    1763
## 17          BPSys2 integer    76.00   106.000   116.000   128.000    226.000 1.184758e+02 1.749133e+01  8353    1647
## 18          BPDia2 integer     0.00    60.000    68.000    76.000    118.000 6.766455e+01 1.441978e+01  8353    1647
## 19          BPSys3 integer    76.00   106.000   116.000   126.000    226.000 1.179292e+02 1.717719e+01  8365    1635
## 20          BPDia3 integer     0.00    60.000    68.000    76.000    116.000 6.729874e+01 1.495839e+01  8365    1635
## 21    Testosterone numeric     0.25    17.700    43.820   362.410   1795.600 1.978980e+02 2.265045e+02  4126    5874
## 22      DirectChol numeric     0.39     1.090     1.290     1.580      4.030 1.364865e+00 3.992581e-01  8474    1526
## 23         TotChol numeric     1.53     4.110     4.780     5.530     13.650 4.879220e+00 1.075583e+00  8474    1526
## 24       UrineVol1 integer     0.00    50.000    94.000   164.000    510.000 1.185161e+02 9.033648e+01  9013     987
## 25      UrineFlow1 numeric     0.00     0.403     0.699     1.221     17.167 9.792946e-01 9.495143e-01  8397    1603
## 26       UrineVol2 integer     0.00    52.000    95.000   171.750    409.000 1.196759e+02 9.016005e+01  1478    8522
## 27      UrineFlow2 numeric     0.00     0.475     0.760     1.513     13.692 1.149372e+00 1.072948e+00  1476    8524
## 28     DiabetesAge integer     1.00    40.000    50.000    58.000     80.000 4.842289e+01 1.568050e+01   629    9371
## 29 DaysPhysHlthBad integer     0.00     0.000     0.000     3.000     30.000 3.334838e+00 7.400700e+00  7532    2468
## 30 DaysMentHlthBad integer     0.00     0.000     0.000     4.000     30.000 4.126493e+00 7.832971e+00  7534    2466
## 31    nPregnancies integer     1.00     2.000     3.000     4.000     32.000 3.026882e+00 1.795341e+00  2604    7396
## 32         nBabies integer     0.00     2.000     2.000     3.000     12.000 2.456954e+00 1.315227e+00  2416    7584
## 33      Age1stBaby integer    14.00    19.000    22.000    26.000     39.000 2.264968e+01 4.772509e+00  1884    8116
## 34   SleepHrsNight integer     2.00     6.000     7.000     8.000     12.000 6.927531e+00 1.346729e+00  7755    2245
## 35  PhysActiveDays integer     1.00     2.000     3.000     5.000      7.000 3.743513e+00 1.836358e+00  4663    5337
## 36   TVHrsDayChild integer     0.00     1.000     2.000     3.000      6.000 1.938744e+00 1.434431e+00   653    9347
## 37 CompHrsDayChild integer     0.00     0.000     1.000     6.000      6.000 2.197550e+00 2.516667e+00   653    9347
## 38      AlcoholDay integer     1.00     1.000     2.000     3.000     82.000 2.914123e+00 3.182672e+00  4914    5086
## 39     AlcoholYear integer     0.00     3.000    24.000   104.000    364.000 7.510165e+01 1.030337e+02  5922    4078
## 40        SmokeAge integer     6.00    15.000    17.000    19.000     72.000 1.782662e+01 5.326660e+00  3080    6920
## 41   AgeFirstMarij integer     1.00    15.000    16.000    19.000     48.000 1.702283e+01 3.895010e+00  2891    7109
## 42     AgeRegMarij integer     5.00    15.000    17.000    19.000     52.000 1.769107e+01 4.806103e+00  1366    8634
## 43          SexAge integer     9.00    15.000    17.000    19.000     50.000 1.742870e+01 3.716551e+00  5540    4460
## 44 SexNumPartnLife integer     0.00     2.000     5.000    12.000   2000.000 1.508507e+01 5.784643e+01  5725    4275
## 45  SexNumPartYear integer     0.00     1.000     1.000     1.000     69.000 1.342330e+00 2.782688e+00  4928    5072</code></pre>
<p>Let us create a NHANES dataset without duplicated IDs and only adults:</p>
<pre class="r"><code>NHANES &lt;-
  NHANES %&gt;%
  distinct(ID, .keep_all = TRUE) 

#create a dataset of only adults
NHANES_adult &lt;- 
  NHANES %&gt;%
  filter( 
    Age &gt;= 18
  ) %&gt;%
  drop_na(Height)

glimpse(NHANES_adult)</code></pre>
<pre><code>## Rows: 4,790
## Columns: 76
## $ ID               &lt;int&gt; 51624, 51630, 51647, 51654, 51656, 51657, 51666, 51667, 51677, 51678, 51685, 51691, 51692, 51694, 51701…
## $ SurveyYr         &lt;fct&gt; 2009_10, 2009_10, 2009_10, 2009_10, 2009_10, 2009_10, 2009_10, 2009_10, 2009_10, 2009_10, 2009_10, 2009…
## $ Gender           &lt;fct&gt; male, female, female, male, male, male, female, male, male, male, female, female, male, male, male, mal…
## $ Age              &lt;int&gt; 34, 49, 45, 66, 58, 54, 58, 50, 33, 60, 56, 57, 54, 38, 36, 44, 64, 26, 59, 49, 51, 28, 37, 28, 32, 25,…
## $ AgeDecade        &lt;fct&gt;  30-39,  40-49,  40-49,  60-69,  50-59,  50-59,  50-59,  50-59,  30-39,  60-69,  50-59,  50-59,  50-59,…
## $ AgeMonths        &lt;int&gt; 409, 596, 541, 795, 707, 654, 700, 603, 404, 721, 677, 694, 655, 458, 434, 539, 771, 319, 718, 593, 614…
## $ Race1            &lt;fct&gt; White, White, White, White, White, White, Mexican, White, White, White, White, White, Hispanic, White, …
## $ Race3            &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ Education        &lt;fct&gt; High School, Some College, College Grad, Some College, College Grad, 9 - 11th Grade, High School, Some …
## $ MaritalStatus    &lt;fct&gt; Married, LivePartner, Married, Married, Divorced, Married, Married, NeverMarried, Married, Married, Mar…
## $ HHIncome         &lt;fct&gt; 25000-34999, 35000-44999, 75000-99999, 25000-34999, more 99999, 65000-74999, 75000-99999, 15000-19999, …
## $ HHIncomeMid      &lt;int&gt; 30000, 40000, 87500, 30000, 100000, 70000, 87500, 17500, 30000, 17500, 87500, NA, 60000, 22500, 70000, …
## $ Poverty          &lt;dbl&gt; 1.36, 1.91, 5.00, 2.20, 5.00, 2.20, 2.03, 1.24, 1.27, 1.03, 5.00, NA, 3.28, 1.15, 2.20, 1.81, 0.69, 5.0…
## $ HomeRooms        &lt;int&gt; 6, 5, 6, 5, 10, 6, 10, 4, 11, 5, 10, 9, 3, 6, 6, 10, 4, 4, 4, 10, 5, 3, 9, 4, 5, 6, 4, 8, 1, 4, 7, 4, 3…
## $ HomeOwn          &lt;fct&gt; Own, Rent, Own, Own, Rent, Rent, Rent, Rent, Own, Own, Own, Own, Rent, Own, Rent, Rent, Rent, Own, Rent…
## $ Work             &lt;fct&gt; NotWorking, NotWorking, Working, NotWorking, Working, Working, Looking, Looking, Working, Working, NotW…
## $ Weight           &lt;dbl&gt; 87.4, 86.7, 75.7, 68.0, 78.4, 74.7, 57.5, 84.1, 93.8, 74.6, 57.5, 51.0, 113.9, 117.3, 79.2, 86.5, 62.8,…
## $ Length           &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ HeadCirc         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ Height           &lt;dbl&gt; 164.7, 168.4, 166.7, 169.5, 181.9, 169.4, 148.1, 177.8, 181.3, 169.9, 170.7, 157.1, 177.1, 180.9, 174.7…
## $ BMI              &lt;dbl&gt; 32.22, 30.57, 27.24, 23.67, 23.69, 26.03, 26.22, 26.60, 28.54, 25.84, 19.73, 20.66, 36.32, 35.84, 25.95…
## $ BMICatUnder20yrs &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ BMI_WHO          &lt;fct&gt; 30.0_plus, 30.0_plus, 25.0_to_29.9, 18.5_to_24.9, 18.5_to_24.9, 25.0_to_29.9, 25.0_to_29.9, 25.0_to_29.…
## $ Pulse            &lt;int&gt; 70, 86, 62, 60, 62, 76, 94, 74, 96, 84, 64, 70, 64, 60, 68, 80, 94, 94, 84, 70, 100, 74, 82, 60, 50, 62…
## $ BPSysAve         &lt;int&gt; 113, 112, 118, 111, 104, 134, 127, 142, 128, 152, 95, 122, 90, 147, 117, 144, 130, 106, 150, 122, 105, …
## $ BPDiaAve         &lt;int&gt; 85, 75, 64, 63, 74, 85, 83, 68, 74, 100, 69, 89, 41, 81, 80, 88, 65, 77, 0, 92, 67, 65, 60, 69, 64, 68,…
## $ BPSys1           &lt;int&gt; 114, 118, 106, 124, 108, 136, NA, 138, 126, 154, 94, 122, 94, 160, 114, 140, 138, 114, 144, 126, 98, 10…
## $ BPDia1           &lt;int&gt; 88, 82, 62, 64, 76, 86, NA, 66, 80, 98, 74, 82, 48, 84, 86, 90, 72, 78, 0, 94, 66, 62, 60, 72, 70, 82, …
## $ BPSys2           &lt;int&gt; 114, 108, 118, 108, 104, 132, 134, 142, 128, 150, 94, 128, 90, 150, 114, 146, 132, 106, 150, 118, 106, …
## $ BPDia2           &lt;int&gt; 88, 74, 68, 62, 72, 88, 82, 74, 74, 98, 70, 88, 42, 80, 78, 92, 62, 78, 0, 90, 68, 64, 58, 68, 62, 76, …
## $ BPSys3           &lt;int&gt; 112, 116, 118, 114, 104, 136, 120, 142, NA, 154, 96, 116, 90, 144, 120, 142, 128, 106, 150, 126, 104, 9…
## $ BPDia3           &lt;int&gt; 82, 76, 60, 64, 76, 82, 84, 62, NA, 102, 68, 90, 40, 82, 82, 84, 68, 76, 0, 94, 66, 66, 62, 70, 66, 60,…
## $ Testosterone     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ DirectChol       &lt;dbl&gt; 1.29, 1.16, 2.12, 0.67, 0.96, 1.16, 1.14, 1.06, 0.91, 1.34, 2.22, 1.53, 1.60, 0.93, 1.11, 0.67, 1.37, 1…
## $ TotChol          &lt;dbl&gt; 3.49, 6.70, 5.82, 4.99, 4.24, 6.41, 4.78, 5.22, 5.59, 6.39, 5.79, 5.04, 4.81, 4.68, 5.12, 5.61, 4.16, 5…
## $ UrineVol1        &lt;int&gt; 352, 77, 106, 113, 163, 215, 29, 64, 155, 238, 26, 133, 168, 73, 344, 86, 127, 70, 42, 105, 131, 57, 45…
## $ UrineFlow1       &lt;dbl&gt; NA, 0.094, 1.116, 0.489, NA, 0.903, 0.299, 0.190, 0.574, NA, 0.194, 2.293, 0.866, 0.468, 1.600, 0.628, …
## $ UrineVol2        &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 86, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 50, NA, NA, NA,…
## $ UrineFlow2       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0.430, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1.000, NA, N…
## $ Diabetes         &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, No, No, No, Yes, Yes, No, Yes, No, No, No, No, No, No, …
## $ DiabetesAge      &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 35, 61, NA, 51, NA, NA, NA, NA, NA, NA, NA,…
## $ HealthGen        &lt;fct&gt; Good, Good, Vgood, Vgood, Vgood, Fair, NA, Good, Fair, Vgood, Good, Excellent, Good, Poor, Good, Fair, …
## $ DaysPhysHlthBad  &lt;int&gt; 0, 0, 0, 10, 0, 4, NA, 0, 3, 7, 3, 0, 0, 3, 0, 2, 0, 0, NA, 3, 0, 30, 0, 0, 15, 15, 2, 0, 0, NA, NA, 5,…
## $ DaysMentHlthBad  &lt;int&gt; 15, 10, 3, 0, 0, 0, NA, 0, 7, 0, 0, 0, 0, 4, 0, 30, 0, 2, NA, 0, 25, 10, 0, 12, 4, 0, 0, 5, 30, 0, NA, …
## $ LittleInterest   &lt;fct&gt; Most, Several, None, None, None, None, NA, None, Several, None, None, None, Several, Several, None, Non…
## $ Depressed        &lt;fct&gt; Several, Several, None, None, None, None, NA, None, None, None, None, None, None, None, None, Most, Non…
## $ nPregnancies     &lt;int&gt; NA, 2, 1, NA, NA, NA, NA, NA, NA, NA, 4, 2, NA, NA, NA, NA, 6, NA, NA, NA, 4, NA, 4, 1, NA, NA, NA, NA,…
## $ nBabies          &lt;int&gt; NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, 3, 2, NA, NA, NA, NA, 6, NA, NA, NA, 3, NA, 2, 1, NA, NA, NA, NA…
## $ Age1stBaby       &lt;int&gt; NA, 27, NA, NA, NA, NA, NA, NA, NA, NA, 26, 32, NA, NA, NA, NA, 19, NA, NA, NA, 22, NA, 32, NA, NA, NA,…
## $ SleepHrsNight    &lt;int&gt; 4, 8, 8, 7, 5, 4, 5, 7, 6, 6, 7, 8, 6, 5, 6, 4, 5, 7, 5, 6, 7, 6, 6, 6, 6, 8, 4, 6, 8, 9, 6, 6, 7, 9, 8…
## $ SleepTrouble     &lt;fct&gt; Yes, Yes, No, No, No, Yes, No, No, No, Yes, No, No, Yes, No, No, Yes, No, No, Yes, No, No, No, No, No, …
## $ PhysActive       &lt;fct&gt; No, No, Yes, Yes, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, No, Yes, No, Yes, Yes, No, Yes, Yes, No, Y…
## $ PhysActiveDays   &lt;int&gt; NA, NA, 5, 7, 5, 1, 2, 7, NA, NA, 7, 3, 3, NA, 2, NA, 4, 1, NA, 7, 6, NA, 5, NA, 3, 4, NA, 4, NA, NA, 2…
## $ TVHrsDay         &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ CompHrsDay       &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ TVHrsDayChild    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ CompHrsDayChild  &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ Alcohol12PlusYr  &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, NA, No, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, No, Yes, NA, Yes, Yes, Yes…
## $ AlcoholDay       &lt;int&gt; NA, 2, 3, 1, 2, 6, NA, NA, 3, 6, 1, 1, 2, NA, 12, NA, NA, 4, NA, 6, 1, 3, 2, 1, 12, 5, 3, 1, NA, NA, NA…
## $ AlcoholYear      &lt;int&gt; 0, 20, 52, 100, 104, 364, NA, 0, 104, 36, 12, 312, 156, 0, 104, 0, NA, 104, NA, 52, 24, 240, 12, 12, 26…
## $ SmokeNow         &lt;fct&gt; No, Yes, NA, No, NA, NA, Yes, NA, No, No, NA, No, NA, NA, NA, Yes, NA, NA, NA, Yes, NA, Yes, NA, NA, Ye…
## $ Smoke100         &lt;fct&gt; Yes, Yes, No, Yes, No, No, Yes, No, Yes, Yes, No, Yes, No, No, No, Yes, No, No, No, Yes, No, Yes, No, N…
## $ Smoke100n        &lt;fct&gt; Smoker, Smoker, Non-Smoker, Smoker, Non-Smoker, Non-Smoker, Smoker, Non-Smoker, Smoker, Smoker, Non-Smo…
## $ SmokeAge         &lt;int&gt; 18, 38, NA, 13, NA, NA, 17, NA, NA, 16, NA, 18, NA, NA, NA, 16, NA, NA, NA, 35, NA, NA, NA, NA, 17, 17,…
## $ Marijuana        &lt;fct&gt; Yes, Yes, Yes, NA, Yes, Yes, NA, No, No, NA, No, Yes, No, No, Yes, Yes, NA, Yes, NA, No, Yes, Yes, No, …
## $ AgeFirstMarij    &lt;int&gt; 17, 18, 13, NA, 19, 15, NA, NA, NA, NA, NA, 18, NA, NA, 22, 16, NA, 14, NA, NA, 21, 14, NA, NA, 16, 13,…
## $ RegularMarij     &lt;fct&gt; No, No, No, NA, Yes, Yes, NA, No, No, NA, No, No, No, No, Yes, No, NA, Yes, NA, No, No, Yes, No, No, Ye…
## $ AgeRegMarij      &lt;int&gt; NA, NA, NA, NA, 20, 15, NA, NA, NA, NA, NA, NA, NA, NA, 25, NA, NA, 15, NA, NA, NA, 15, NA, NA, 16, 16,…
## $ HardDrugs        &lt;fct&gt; Yes, Yes, No, No, Yes, Yes, NA, No, No, No, No, No, No, No, Yes, No, No, No, NA, Yes, No, Yes, No, No, …
## $ SexEver          &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, NA, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, NA, Yes, Yes, Y…
## $ SexAge           &lt;int&gt; 16, 12, 13, 17, 22, 12, NA, NA, 27, 20, 20, 18, 14, 23, 17, 15, NA, 15, NA, 14, 20, 21, 16, 24, 17, 15,…
## $ SexNumPartnLife  &lt;int&gt; 8, 10, 20, 15, 7, 100, NA, 9, 1, 1, 2, 5, 20, 1, 20, 12, 0, 9, NA, 1, 8, 1, 10, 1, 15, 6, 4, 1, 90, NA,…
## $ SexNumPartYear   &lt;int&gt; 1, 1, 0, NA, 1, 1, NA, 1, 1, NA, 1, 1, 2, 1, 3, 1, NA, 1, NA, 0, 1, 1, 1, 1, 1, 1, 2, 1, 0, NA, NA, 1, …
## $ SameSex          &lt;fct&gt; No, Yes, Yes, No, No, No, NA, No, No, No, No, No, No, No, No, No, No, No, NA, No, Yes, No, No, No, No, …
## $ SexOrientation   &lt;fct&gt; Heterosexual, Heterosexual, Bisexual, NA, Heterosexual, Heterosexual, NA, Heterosexual, Heterosexual, N…
## $ PregnantNow      &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, No, NA, NA, NA, NA, No, No, NA, NA,…</code></pre>
<p>For now, we will <strong>treat</strong> this dataset as our <strong>Population</strong>. So each variable in the dataset is a population for that particular quantity/category, with appropriate <em>population parameters</em> such as means, sd-s, and proportions. Let us calculate the <strong>population parameters</strong> for the <code>Height</code> data:</p>
<pre class="r"><code>pop_mean_height &lt;- mean(~ Height, data = NHANES_adult)
pop_sd_height &lt;- sd(~ Height, data = NHANES_adult)

pop_mean_height</code></pre>
<pre><code>## [1] 168.3497</code></pre>
<pre class="r"><code>pop_sd_height</code></pre>
<pre><code>## [1] 10.15705</code></pre>
<p>Now, we will sample <strong>ONCE</strong> from the NHANES <code>Height</code> variable. Let us take a sample of <code>sample size</code> 50. We will compare <strong>sample statistics</strong> with <strong>population parameters</strong> on the basis of this ONE sample of 50:</p>
<pre class="r"><code>sample_height &lt;- sample(NHANES_adult, size = 50) %&gt;% select(Height)
sample_height</code></pre>
<pre><code>## # A tibble: 50 × 1
##    Height
##     &lt;dbl&gt;
##  1   172 
##  2   159.
##  3   171 
##  4   159.
##  5   156.
##  6   170.
##  7   148.
##  8   159.
##  9   168.
## 10   159.
## # … with 40 more rows</code></pre>
<pre class="r"><code>sample_mean_height &lt;- mean(~ Height, data = sample_height)
sample_mean_height</code></pre>
<pre><code>## [1] 165.866</code></pre>
<pre class="r"><code># Plotting the histogram of this sample
sample_height %&gt;% gf_histogram(~ Height) %&gt;% 
  gf_vline(xintercept = sample_mean_height, color = &quot;red&quot;) %&gt;% 
  gf_vline(xintercept = pop_mean_height, colour = &quot;blue&quot;) %&gt;% 
  gf_text(1 ~ (pop_mean_height + 5), label = &quot;Population Mean Height&quot;, color = &quot;blue&quot;) %&gt;% 
  gf_text(2 ~ (sample_mean_height-5), label = &quot;Sample Mean Height&quot;, color = &quot;red&quot;)</code></pre>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-5"></span>
<img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-5-1.png" alt="Single-Sample Mean and Population Mean" width="672" id="fig-unnamed-chunk-5-1" />
<p class="caption">
Figure 1: Single-Sample Mean and Population Mean
</p>
</div>
<p>OK, so the <code>sample_mean_height</code> is not too far from the <code>pop_mean_height</code>. Is this always true? Let us check: we will create 500 samples each of size 50. And calculate their mean as the <em>sample statistic</em>, giving us a dataframe containing 5000 <code>sample means</code>. We will then compare if these 500 means are close to the <code>pop_mean_height</code>:</p>
<pre class="r"><code>sample_height_500 &lt;- do(500) * {
  sample(NHANES_adult, size = 50) %&gt;%
    select(Height) %&gt;%
    summarise(
      sample_mean_500 = mean(Height),
      sample_min_500 = min(Height),
      sample_max_500 = max(Height))
}

head(sample_height_500)</code></pre>
<pre><code>## # A tibble: 6 × 5
##   sample_mean_500 sample_min_500 sample_max_500  .row .index
##             &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;
## 1            167.           144.           189.     1      1
## 2            167.           144.           191.     1      2
## 3            167.           147.           192.     1      3
## 4            170.           147.           192.     1      4
## 5            169            149.           191.     1      5
## 6            166.           143.           188.     1      6</code></pre>
<pre class="r"><code>dim(sample_height_500)</code></pre>
<pre><code>## [1] 500   5</code></pre>
<pre class="r"><code>sample_height_500 %&gt;%
  gf_point(.index ~ sample_mean_500, color = &quot;red&quot;) %&gt;%
  gf_segment(
    .index + .index ~ sample_min_500 + sample_max_500,
    color = &quot;red&quot;,
    size = 0.3,
    alpha = 0.3,
    ylab = &quot;Sample Index (1-500)&quot;,
    xlab = &quot;Sample Means&quot;
  ) %&gt;%
  gf_vline(xintercept = ~ pop_mean_height, color = &quot;blue&quot;) %&gt;%
  gf_label(-15 ~ pop_mean_height, label = &quot;Population Mean&quot;, color = &quot;blue&quot;)</code></pre>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-6"></span>
<img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-6-1.png" alt="Multiple Sample-Means and Population Mean" width="672" id="fig-unnamed-chunk-6-1" />
<p class="caption">
Figure 2: Multiple Sample-Means and Population Mean
</p>
</div>
<p>The <code>sample_mean</code>s (red dots), are themselves random because the samples are random, of course. It appears that they are generally in the vicinity of the <code>pop_mean</code> (blue line).</p>
<div id="distribution-of-sample-means" class="section level3">
<h3>Distribution of Sample-Means</h3>
<p>Since the <strong>sample-means</strong> are themselves random variables, let’s plot the <strong>distribution</strong> of these 5000 sample-means themselves, called a <strong>a distribution of sample-means</strong>.</p>
<div class="Note">
<p>NOTE: this <strong>a distribution of sample-means</strong> will <em>itself</em> have a mean and standard deviation. Do not get confused ;-D</p>
</div>
<p>We will also plot the position of the population mean <code>pop_mean_height</code> parameter, the means of the <code>Height</code> variable.</p>
<pre class="r"><code>sample_height_500 %&gt;% gf_dhistogram(~ sample_mean_500) %&gt;% 
  gf_vline(xintercept = pop_mean_height, color = &quot;blue&quot;) %&gt;% 
   gf_label(0.01 ~ pop_mean_height, label = &quot;Population Mean&quot;, color = &quot;blue&quot;)</code></pre>
<div class="figure"><span style="display:block;" id="fig:Sampling-Mean-Distribution"></span>
<img src="{{< blogdown/postref >}}index_files/figure-html/Sampling-Mean-Distribution-1.png" alt="Sampling Mean Distribution" width="768" height="50%" id="fig-sampling-mean-distribution-1" />
<p class="caption">
Figure 3: Sampling Mean Distribution
</p>
</div>
<p>How does this <strong>distribution of sample-means</strong> compare with that of the overall distribution of the population?</p>
<pre class="r"><code>sample_height_500 %&gt;% gf_dhistogram(~ sample_mean_500) %&gt;% 
  gf_vline(xintercept = pop_mean_height, color = &quot;blue&quot;) %&gt;% 
   gf_label(0.01 ~ pop_mean_height, label = &quot;Population Mean&quot;, color = &quot;blue&quot;) %&gt;% 

  ## Add the population histogram
  gf_histogram(~ Height, data = NHANES_adult, alpha = 0.2, fill = &quot;blue&quot;, bins = 50) %&gt;% 
  gf_label(0.025 ~ (pop_mean_height + 20), label = &quot;Population Distribution&quot;, color = &quot;blue&quot;)</code></pre>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-7"></span>
<img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-7-1.png" alt="Sampling Means and Population Distributions" width="672" id="fig-unnamed-chunk-7-1" />
<p class="caption">
Figure 4: Sampling Means and Population Distributions
</p>
</div>
</div>
<div id="central-limit-theorem" class="section level3">
<h3>Central limit theorem</h3>
<p>We see in the Figure above that</p>
<ul>
<li><p>the <em>distribution of sample-means</em> is centered around the <code>pop_mean</code>.</p></li>
<li><p>that the <em>distribution of sample-means</em> has mean = <code>pop_mean</code></p></li>
<li><p>That the standard deviation of the <em>distribution of sample means</em> is less than that of the original population. But exactly what is it?</p></li>
<li><p>And what is the kind of distribution?</p></li>
</ul>
<p>One more experiment.</p>
<p>Now let’s repeatedly sample <code>Height</code> and compute the sample mean, and look at the resulting histograms and Q-Q plots. ( Q-Q plots check whether a certain distribution is close to being normal or not.)</p>
<p>We will use sample sizes of <code>c(16, 32, 64, 128)</code> and generate 1000 samples each time, take the means and plot these 1000 means:</p>
<pre class="r"><code>set.seed(12345)


samples_height_16 &lt;- do(1000,) * mean(resample(NHANES_adult$Height, size = 16))
samples_height_32 &lt;- do(1000) * mean(resample(NHANES_adult$Height, size = 32))
samples_height_64 &lt;- do(1000) * mean(resample(NHANES_adult$Height, size = 64))
samples_height_128 &lt;- do(1000) * mean(resample(NHANES_adult$Height, size = 128))

# Quick Check
head(samples_height_16)</code></pre>
<pre><code>##       mean
## 1 168.0500
## 2 166.1000
## 3 165.5375
## 4 167.5625
## 5 165.2375
## 6 169.0250</code></pre>
<pre class="r"><code>### do(1000,) * mean(resample(NHANES_adult$Height, size = 16)) produces a data frame with a variable named mean.
###</code></pre>
<p>Now let’s create separate Q-Q plots for the different sample sizes.</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Let us plot their individual histograms to compare them:</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>And if we overlay the histograms:</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>This shows that the results become more normally distributed (i.e. following the straight line) as the samples get larger. Hence we learn that:</p>
<ul>
<li>the sample-means are normally distributed around the <em>population mean</em>. This is because when we sample from the population, many values will be close to the <em>population mean</em>, and values far away from the mean will be increasingly scarce.</li>
</ul>
<pre class="r"><code>mean(~ mean, data  = samples_height_16)</code></pre>
<pre><code>## [1] 168.306</code></pre>
<pre class="r"><code>mean(~ mean, data  = samples_height_32)</code></pre>
<pre><code>## [1] 168.4349</code></pre>
<pre class="r"><code>mean(~ mean, data  = samples_height_64)</code></pre>
<pre><code>## [1] 168.3184</code></pre>
<pre class="r"><code>mean(~ mean, data  = samples_height_128)</code></pre>
<pre><code>## [1] 168.366</code></pre>
<pre class="r"><code>pop_mean_height</code></pre>
<pre><code>## [1] 168.3497</code></pre>
<ul>
<li><p>the sample-means become “more normally distributed” with sample length, as shown by the (small but definite) improvements in the Q-Q plots with sample-size.</p></li>
<li><p>the sample-mean distributions narrow with sample length.</p></li>
</ul>
<p>This is regardless of the distribution of the <em>population</em> itself. ( The <code>Height</code> variable seems to be normally distributed at population level. We will try other non-normal population variables as an exercise). This is the ** Central Limit Theorem (CLT) **.</p>
<p>As we saw above, the standard deviations of the sample-mean distributions reduce with sample size. In fact their SDs are defined by:</p>
<p><code>sd = pop_sd/sqrt(sample_size)</code> where sample-size here is one of <code>c(16,32,64,128)</code></p>
<pre class="r"><code>sd(~ mean, data  = samples_height_16)</code></pre>
<pre><code>## [1] 2.578355</code></pre>
<pre class="r"><code>sd(~ mean, data  = samples_height_32)</code></pre>
<pre><code>## [1] 1.834979</code></pre>
<pre class="r"><code>sd(~ mean, data  = samples_height_64)</code></pre>
<pre><code>## [1] 1.280014</code></pre>
<pre class="r"><code>sd(~ mean, data  = samples_height_128)</code></pre>
<pre><code>## [1] 0.9096318</code></pre>
<p>The standard deviation of the <strong>sample-mean distribution</strong> is called the <strong>Standard Error</strong>. This statistic derived from the sample, will help us infer our population parameters with a precise estimate of the <em>uncertainty</em> involved.</p>
<p><span class="math display">\[
Standard\ Error\ \pmb {se} = \frac{population\ sd}{\sqrt[]{sample\ size}}\\\
\pmb {se} = \frac{\sigma}{\sqrt[]{n}}
\]</span></p>
<p>In our sampling experiments, the Standard Errors evaluate to:</p>
<pre class="r"><code>pop_sd_height &lt;- sd(~ Height, data = NHANES_adult)

pop_sd_height/sqrt(16)</code></pre>
<pre><code>## [1] 2.539262</code></pre>
<pre class="r"><code>pop_sd_height/sqrt(32)</code></pre>
<pre><code>## [1] 1.795529</code></pre>
<pre class="r"><code>pop_sd_height/sqrt(64)</code></pre>
<pre><code>## [1] 1.269631</code></pre>
<pre class="r"><code>pop_sd_height/sqrt(128)</code></pre>
<pre><code>## [1] 0.8977646</code></pre>
<p>As seen, these are identical to the Standard Deviations of the individual sample-mean distributions.</p>
</div>
</div>
<div id="confidence-intervals" class="section level2">
<h2>Confidence intervals</h2>
<p>When we work with samples, we want to be able to speak with a certain degree of confidence about the <strong>population mean</strong>, based on the evaluation of <strong>one</strong> sample mean,not a whole large number of them.
Give that sample-means are normally distributed around the <strong>population means</strong>, we can say that <span class="math inline">\(68%\)</span> of <em>all possible sample-mean</em> lie within $ +/- 1 SE $ of the <em>population mean</em>; and further that <span class="math inline">\(95%\)</span> of of <em>all possible sample-mean</em> lie within $ +/- 1.5* SE $ of the <em>population mean</em>.</p>
<p>These two intervals <strong>[sample-mean +/- SE]</strong> and <strong>[sample-mean +/- 1.5SE]</strong> are called the <strong>confidence intervals</strong> for the population mean, at levels 68% and 95% respectively.</p>
<p>Thus if we want to estimate a <em>population mean</em>:
- we take one sample from the population<br />
- we calculate the sample-mean
- we calculate the sample-sd
- We calculate the Standard Error as <span class="math inline">\(\frac{sample-sd}{\sqrt[]{n}}\)</span>
- We calculate 95% confidence intervals for the <em>population mean</em> based on the formula above.</p>
</div>
<div id="a-sampling-workflow-in-orange" class="section level2">
<h2>A Sampling Workflow in Orange</h2>
</div>
<div id="a-sampling-workflow-in-radiant" class="section level2">
<h2>A Sampling Workflow in Radiant</h2>
</div>
<div id="a-sampling-workflow-in-r" class="section level2">
<h2>A Sampling Workflow in R</h2>
<a onclick="fetch(&#39;data:text/x-markdown;base64,LS0tDQp0aXRsZTogIlNhbXBsaW5nIg0KYXV0aG9yOiAiQXJ2aW5kIFZlbmthdGFkcmkiDQpkYXRlOiAnYHIgU3lzLkRhdGUoKWAnDQpvdXRwdXQ6DQogIGh0bWxfZG9jdW1lbnQ6DQogICAgdGhlbWU6IGZsYXRseQ0KICAgIHRvYzogVFJVRQ0KICAgIHRvY19mbG9hdDogVFJVRQ0KICAgIHRvY19kZXB0aDogMg0KICAgIGRmX3ByaW50OiBwYWdlZA0KICAgIG51bWJlcl9zZWN0aW9uczogVFJVRQ0KICAgIGNvZGVfZm9sZGluZzogaGlkZQ0KICAgIGNvZGVfZG93bmxvYWQ6IFRSVUUNCmVkaXRvcl9vcHRpb25zOiANCiAgbWFya2Rvd246IA0KICAgIHdyYXA6IDcyDQotLS0NCg0KYGBge3Igc2V0dXAsIGluY2x1ZGU9RkFMU0V9DQprbml0cjo6b3B0c19jaHVuayRzZXQoZWNobyA9IFRSVUUpDQpsaWJyYXJ5KG1vc2FpYykNCmxpYnJhcnkobW9zYWljRGF0YSkNCg0KbGlicmFyeShOSEFORVMpDQpsaWJyYXJ5KGNvd3Bsb3QpDQoNCmBgYA0KDQojIEludHJvZHVjdGlvbg0KDQpDb250aW51aW5nIHRvIHRyZWF0IHRoZSBgTkhBTkVTYCBkYXRhc2V0IGFzIGEgKipwb3B1bGF0aW9uKiosIFdlIHdpbGwgdHJ5IHRvIHJlcGxpY2F0ZSB0aGUgcHJvY2VzcyBvZiBzYW1wbGluZyBhbmQgQ0xUIGZvciBhbm90aGVyIHZhcmlhYmxlIGluIHRoZSBOSEFORVMgdmFyaWFibGUsIGBBbGNvaG9sWWVhcmAuDQoNCiMjIFN1bW1hcnkgZm9yIGBBbGNvaG9sWWVhcmAgcG9wdWxhdGlvbg0KDQpgYGB7cn0NCg0KYGBgDQoNCg0KDQojIyBTYW1wbGluZyBgQWxjb2hvbFllYXJgDQoNCmBgYHtyfQ0KDQpgYGANCg0KIyMgRGlzdHJpYnV0aW9uIGFuZCBRUSBQbG90IGZvciB0aGUgc2FtcGxlDQoNCmBgYHtyfQ0KDQpgYGANCg0KDQoNCg0KDQoNCiMjIEVzdGltYXRpbmcgUG9wdWxhdGlvbiBNZWFuIGFuZCBDb25maWRlbmNlIEludGVydmFsIHVzaW5nIHRoZSBTYW1wbGUNCg0KDQpgYGB7cn0NCg0KYGBgDQoNCiMjIENvbmNsdXNpb24NCg0KDQo=&#39;).then(res =&gt; res.blob()).then(blob =&gt; {&#10;      const downloadURL = window.URL.createObjectURL(blob);&#10;      const a = document.createElement(&#39;a&#39;);&#10;      document.body.appendChild(a);&#10;      a.href = downloadURL;&#10;      a.download = &#39;sampling.Rmd&#39;; a.click();&#10;      window.URL.revokeObjectURL(downloadURL);&#10;      document.body.removeChild(a);&#10;    });">
<button class="btn btn-danger" output_extension=".Rmd"><i class="fa fa-save"></i> Download RMarkdown Workflow</button>
</a>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<ol style="list-style-type: decimal">
<li><p>Diez, David M &amp; Barr, Christopher D &amp; Çetinkaya-Rundel, Mine, <em>OpenIntro Statistics</em>. <a href="https://www.openintro.org/book/os/" class="uri">https://www.openintro.org/book/os/</a></p></li>
<li><p>Stats Test Wizard. <a href="https://www.socscistatistics.com/tests/what_stats_test_wizard.aspx" class="uri">https://www.socscistatistics.com/tests/what_stats_test_wizard.aspx</a></p></li>
<li><p>Diez, David M &amp; Barr, Christopher D &amp; Çetinkaya-Rundel, Mine: <em>OpenIntro Statistics</em>. Available online <a href="https://www.openintro.org/book/os/" class="uri">https://www.openintro.org/book/os/</a></p></li>
<li><p>Måns Thulin, <em>Modern Statistics with R: From wrangling and exploring data to inference and predictive modelling</em> <a href="http://www.modernstatisticswithr.com/" class="uri">http://www.modernstatisticswithr.com/</a></p></li>
<li><p>Jonas Kristoffer Lindeløv, Common statistical tests are linear models (or: how to teach stats) <a href="https://lindeloev.github.io/tests-as-linear/" class="uri">https://lindeloev.github.io/tests-as-linear/</a></p></li>
<li><p>CheatSheet <a href="https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.pdf" class="uri">https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.pdf</a></p></li>
<li><p>Common statistical tests are linear models: a work through by Steve Doogue <a href="https://steverxd.github.io/Stat_tests/" class="uri">https://steverxd.github.io/Stat_tests/</a></p></li>
<li><p>Jeffrey Walker “Elements of Statistical Modeling for Experimental Biology”. <a href="https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/" class="uri">https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/</a></p></li>
</ol>
</div>
