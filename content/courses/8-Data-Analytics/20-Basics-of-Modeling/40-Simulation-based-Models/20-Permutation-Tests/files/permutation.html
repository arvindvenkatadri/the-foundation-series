---
title: "Permutation Tests"
author: "Arvind Venkatadri"
date: "2022-11-29"
output:
  html_document:
    theme: flatly
    toc: TRUE
    toc_float: TRUE
    toc_depth: 2
    df_print: paged
    number_sections: TRUE
    code_folding: hide
    code_download: TRUE
editor_options: 
  markdown: 
    wrap: 72
---



<div id="permutation-tests" class="section level2">
<h2>Permutation Tests</h2>
<div id="case-study-1-hot-wings-orders-vs-gender" class="section level3">
<h3>Case Study-1: Hot Wings Orders vs Gender</h3>
<p>A student conducted a study of hot wings and beer consumption at a Bar.
She asked patrons at the bar to record their consumption of hot wings
and beer over the course of several hours. She wanted to know if people
who ate more hot wings would then drink more beer. In addition, she
investigated whether or not gender had an impact on hot wings or beer
consumption.</p>
<pre class="r"><code>Beerwings &lt;- read.csv(&quot;https://sites.google.com/site/chiharahesterberg/data2/Beerwings.csv&quot;)
inspect(Beerwings)</code></pre>
<pre><code>## 
## categorical variables:  
##     name     class levels  n missing                                  distribution
## 1 Gender character      2 30       0 F (50%), M (50%)                             
## 
## quantitative variables:  
##       name   class min    Q1 median    Q3 max     mean        sd  n missing
## 1       ID integer   1  8.25   15.5 22.75  30 15.50000  8.803408 30       0
## 2 Hotwings integer   4  8.00   12.5 15.50  21 11.93333  4.784554 30       0
## 3     Beer integer   0 24.00   30.0 36.00  48 26.20000 11.842064 30       0</code></pre>
<p>Let us calculate the observed difference in <code>Hotwings</code> consumption
between Males and Females ( <code>Gender</code>)</p>
<pre class="r"><code>mean(Hotwings ~ Gender, data = Beerwings)</code></pre>
<pre><code>##         F         M 
##  9.333333 14.533333</code></pre>
<pre class="r"><code>obs_diff_wings &lt;- mosaic::diffmean(data = Beerwings, Hotwings ~ Gender)
obs_diff_wings </code></pre>
<pre><code>## diffmean 
##      5.2</code></pre>
<pre class="r"><code>gf_boxplot(data = Beerwings, Hotwings ~ Gender, title = &quot;Hotwings Consumption by Gender&quot;)</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-3-1.png" width="50%" height="50%" /></p>
<p>The observed difference in mean consumption of Hotwings between Males
and Females is 5.2. Could this have occurred by chance? Here is our
formulation of the Hypotheses:</p>
<p><span class="math display">\[
NULL\ Hypothesis\ H_0 =&gt; No\ difference\ between\ means\ across\ groups\\
Alternative\ Hypothesis\
H_a =&gt;Significant\ difference\ between\ the\ means\
\]</span></p>
<p>So we perform a Permutation Test to check:</p>
<pre class="r"><code>null_dist_wings &lt;- do(1000) * diffmean(Hotwings ~ shuffle(Gender), data = Beerwings)
null_dist_wings %&gt;% head()</code></pre>
<pre><code>##     diffmean
## 1  1.7333333
## 2  0.4000000
## 3  1.7333333
## 4  1.2000000
## 5  0.2666667
## 6 -3.6000000</code></pre>
<pre class="r"><code>gf_histogram(data = null_dist_wings, ~ diffmean) %&gt;% 
  gf_vline(xintercept = obs_diff_wings, colour = &quot;red&quot;)</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-4-1.png" width="50%" height="50%" /></p>
<pre class="r"><code>prop1(~ diffmean &gt;= obs_diff_wings, data = null_dist_wings)</code></pre>
<pre><code>##   prop_TRUE 
## 0.002997003</code></pre>
<p>The <span class="math inline">\(\color{red}{red\ line}\)</span> shows the actual measured mean difference
in Hot Wings consumption. The probability that our Permutation
distribution is able to equal or exceed that number is <span class="math inline">\(0.001998002\)</span> and
we have to reject the Null Hypothesis that the means are identical.</p>
</div>
<div id="case-study-2-verizon" class="section level3">
<h3>Case Study-2: Verizon</h3>
<pre class="r"><code>verizon &lt;- read.csv(&quot;https://sites.google.com/site/chiharahesterberg/data2/Verizon.csv&quot;)
inspect(verizon)</code></pre>
<pre><code>## 
## categorical variables:  
##    name     class levels    n missing                                  distribution
## 1 Group character      2 1687       0 ILEC (98.6%), CLEC (1.4%)                    
## 
## quantitative variables:  
##   name   class min   Q1 median   Q3   max     mean       sd    n missing
## 1 Time numeric   0 0.75   3.63 7.35 191.6 8.522009 14.78848 1687       0</code></pre>
<pre class="r"><code>mean(Time ~ Group, data = verizon)</code></pre>
<pre><code>##      CLEC      ILEC 
## 16.509130  8.411611</code></pre>
<pre class="r"><code>obs_diff_verizon &lt;- diffmean(Time ~ Group, data = verizon)
obs_diff_verizon</code></pre>
<pre><code>## diffmean 
## -8.09752</code></pre>
<pre class="r"><code>null_dist_verizon &lt;- do(1000) * diffmean(Time ~ shuffle(Group), data = verizon)
gf_histogram(data = null_dist_verizon, ~ diffmean) %&gt;% 
  gf_vline(xintercept = obs_diff_wings, colour = &quot;red&quot;)</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-7-1.png" width="50%" height="50%" /></p>
<pre class="r"><code>prop1(~ diffmean &gt;= obs_diff_wings, data = null_dist_verizon)</code></pre>
<pre><code>##  prop_TRUE 
## 0.01698302</code></pre>
</div>
<div id="case-story-3-recidivism" class="section level3">
<h3>Case Story-3: Recidivism</h3>
<p>Do criminals released after a jail term commit crimes again?</p>
<pre class="r"><code>recidivism &lt;- read.csv(&quot;http://sites.google.com/site/chiharahesterberg/data2/Recidivism.csv&quot;)
inspect(recidivism)</code></pre>
<pre><code>## 
## categorical variables:  
##      name     class levels     n missing                                  distribution
## 1  Gender character      2 17019       3 M (87.7%), F (12.3%)                         
## 2     Age character      5 17019       3 25-34 (36.6%), 35-44 (23.7%) ...             
## 3   Age25 character      2 17019       3 Over 25 (81.9%), Under 25 (18.1%)            
## 4    Race character     10 16988      34 White-NonHispanic (67%) ...                  
## 5 Offense character      2 17022       0 Felony (80.6%), Misdemeanor (19.4%)          
## 6   Recid character      2 17022       0 No (68.4%), Yes (31.6%)                      
## 7    Type character      3 17022       0 No Recidivism (68.4%), New (20.2%) ...       
## 
## quantitative variables:  
##   name   class min  Q1 median  Q3  max     mean       sd    n missing
## 1 Days integer   0 241    418 687 1095 473.3275 283.1393 5386   11636</code></pre>
<p>There are some missing values in the variable <tt> <code>Age25</code></tt>. The
<tt> <code>complete.cases</code></tt> command gives the row numbers where values
are not missing. We create a new data frame omitting the rows where
there is a missing value in the <tt> ‘Age25’ </tt> variable.</p>
<pre class="r"><code>recidivism_na &lt;- recidivism %&gt;% tidyr::drop_na(Age25)</code></pre>
<p>Also, the variable <tt><code>Recid</code></tt> is a factor variable coded “Yes” or
“No”. We convert it to a numeric variable of 1’s and 0’s.</p>
<pre class="r"><code>recidivism_na &lt;- recidivism_na %&gt;% mutate(Recid2 = ifelse(Recid==&quot;Yes&quot;, 1, 0))

obs_diff_recid &lt;- diffmean( Recid2 ~ Age25, data = recidivism_na)
obs_diff_recid</code></pre>
<pre><code>##   diffmean 
## 0.05919913</code></pre>
<pre class="r"><code>null_dist_recid &lt;- do(1000) * diffmean( Recid2 ~ shuffle(Age25), data = recidivism_na)

gf_histogram( ~ diffmean, data = null_dist_recid) %&gt;% 
  gf_vline(xintercept = obs_diff_recid, colour = &quot;red&quot;)</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-10-1.png" width="50%" height="50%" /></p>
</div>
<div id="case-study-4-matched-pairs-results-from-a-diving-championship." class="section level3">
<h3>Case Study-4: Matched Pairs: Results from a diving championship.</h3>
<pre class="r"><code>Diving2017 &lt;- read.csv(&quot;http://sites.google.com/site/chiharahesterberg/data2/Diving2017.csv&quot;)
head(Diving2017)</code></pre>
<pre><code>##               Name     Country Semifinal  Final
## 1 CHEONG Jun Hoong    Malaysia    325.50 397.50
## 2         SI Yajie       China    382.80 396.00
## 3         REN Qian       China    367.50 391.95
## 4       KIM Mi Rae North Korea    346.00 385.55
## 5       WU Melissa   Australia    318.70 370.20
## 6    KIM Kuk Hyang North Korea    360.85 360.00</code></pre>
<pre class="r"><code>inspect(Diving2017)</code></pre>
<pre><code>## 
## categorical variables:  
##      name     class levels  n missing                                  distribution
## 1    Name character     12 12       0  SI Yajie (8.3%) ...                         
## 2 Country character      8 12       0 Canada (16.7%), China (16.7%) ...            
## 
## quantitative variables:  
##        name   class    min       Q1  median      Q3   max    mean       sd  n missing
## 1 Semifinal numeric 313.70 322.2000 325.625 356.575 382.8 338.500 22.94946 12       0
## 2     Final numeric 283.35 318.5875 358.925 387.150 397.5 350.475 40.02204 12       0</code></pre>
<p>The data is made up of <strong>paired</strong> observations per swimmer. So we need
to take the difference between the two swim records for <em>each</em> swimmer
and then shuffle the differences to either polarity. Another way to look
at this is to shuffle the records between <code>Semifinal</code> and <code>Final</code> on a
per Swimmer basis.</p>
<pre class="r"><code>Diving2017</code></pre>
<pre><code>##                      Name     Country Semifinal  Final
## 1        CHEONG Jun Hoong    Malaysia    325.50 397.50
## 2                SI Yajie       China    382.80 396.00
## 3                REN Qian       China    367.50 391.95
## 4              KIM Mi Rae North Korea    346.00 385.55
## 5              WU Melissa   Australia    318.70 370.20
## 6           KIM Kuk Hyang North Korea    360.85 360.00
## 7         ITAHASHI Minami       Japan    313.70 357.85
## 8        BENFEITO Meaghan      Canada    355.15 331.40
## 9          PAMG Pandelela    Malaysia    322.75 322.40
## 10        CHAMANDY Olivia      Canada    320.55 307.15
## 11       PARRATTO Jessica         USA    322.75 302.35
## 12 MURILLO URREA Carolina    Colombia    325.75 283.35</code></pre>
<pre class="r"><code>Diving2017 %&gt;% diffmean(data = ., Final ~ Semifinal, only.2 = FALSE)</code></pre>
<pre><code>##   318.7-313.7  320.55-318.7 322.75-320.55  325.5-322.75  325.75-325.5    346-325.75    355.15-346 360.85-355.15  367.5-360.85 
##        12.350       -63.050         5.225        85.125      -114.150       102.200       -54.150        28.600        31.950 
##   382.8-367.5 
##         4.050</code></pre>
<pre class="r"><code>obs_diff_swim &lt;- mean(~ Final - Semifinal, data = Diving2017)
obs_diff_swim</code></pre>
<pre><code>## [1] 11.975</code></pre>
<pre class="r"><code>polarity &lt;- c(rep(1, 6), rep(-1,6))
polarity</code></pre>
<pre><code>##  [1]  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1</code></pre>
<pre class="r"><code>null_dist_swim &lt;- do(100000) * mean(data = Diving2017, 
                                    ~(Final - Semifinal) * resample(polarity,
                                                    replace = TRUE))
null_dist_swim %&gt;% head()</code></pre>
<pre><code>##         mean
## 1   0.225000
## 2   4.008333
## 3  21.300000
## 4  -4.925000
## 5 -14.008333
## 6   8.050000</code></pre>
<pre class="r"><code>gf_histogram(data = null_dist_swim, ~mean) %&gt;% 
  gf_vline(xintercept = obs_diff_swim, colour = &quot;red&quot;)</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-13-1.png" width="50%" height="50%" /></p>
</div>
<div id="case-study-5-flight-delays" class="section level3">
<h3>Case Study #5: Flight Delays</h3>
<p>LaGuardia Airport (LGA) is one of three major airports that serves the
New York City metropolitan area. In 2008, over 23 million passengers and
over 375 000 planes flew in or out of LGA. United Airlines and America
Airlines are two major airlines that schedule services at LGA. The data
set <code>FlightDelays</code> contains information on all 4029 departures of these
two airlines from LGA during May and June 2009.</p>
<pre class="r"><code>flightDelays &lt;- read.csv(&quot;http://sites.google.com/site/chiharahesterberg/data2/FlightDelays.csv&quot;)

inspect(flightDelays)</code></pre>
<pre><code>## 
## categorical variables:  
##          name     class levels    n missing                                  distribution
## 1     Carrier character      2 4029       0 AA (72.1%), UA (27.9%)                       
## 2 Destination character      7 4029       0 ORD (44.3%), DFW (22.8%), MIA (15.1%) ...    
## 3  DepartTime character      5 4029       0 8-Noon (26.1%), Noon-4pm (26%) ...           
## 4         Day character      7 4029       0 Fri (15.8%), Mon (15.6%), Tue (15.6%) ...    
## 5       Month character      2 4029       0 June (50.4%), May (49.6%)                    
## 6   Delayed30 character      2 4029       0 No (85.2%), Yes (14.8%)                      
## 
## quantitative variables:  
##           name   class min   Q1 median   Q3  max      mean         sd    n missing
## 1           ID integer   1 1008   2015 3022 4029 2015.0000 1163.21645 4029       0
## 2     FlightNo integer  71  371    691  787 2255  827.1035  551.30939 4029       0
## 3 FlightLength integer  68  155    163  228  295  185.3011   41.78783 4029       0
## 4        Delay integer -19   -6     -3    5  693   11.7379   41.63050 4029       0</code></pre>
<p>The variables in the <code>flightDelays</code> dataset are:</p>
<table>
<caption>flightDelay dataset variables</caption>
<colgroup>
<col width="23%" />
<col width="76%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Carrier</td>
<td>UA=United Airlines, AA=American Airlines</td>
</tr>
<tr class="even">
<td>FlightNo</td>
<td>Flight number</td>
</tr>
<tr class="odd">
<td>Destination</td>
<td>Airport code</td>
</tr>
<tr class="even">
<td>DepartTime</td>
<td>Scheduled departure time in 4 h intervals</td>
</tr>
<tr class="odd">
<td>Day</td>
<td>Day of the Week</td>
</tr>
<tr class="even">
<td>Month</td>
<td>May or June</td>
</tr>
<tr class="odd">
<td>Delay</td>
<td>Minutes flight delayed (negative indicates early departure)</td>
</tr>
<tr class="even">
<td>Delayed30</td>
<td>Departure delayed more than 30 min? Yes or No</td>
</tr>
<tr class="odd">
<td>FlightLength</td>
<td>Length of time of flight (minutes)</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>Let us compute the proportion of times that each carrier’s flights
was delayed more than 20 min. We will conduct a two-sided test to
see if the difference in these proportions is statistically
significant.</li>
</ol>
<pre class="r"><code>prop(data = flightDelays, Delay &gt;= 20 ~ Carrier)</code></pre>
<pre><code>## prop_TRUE.AA prop_TRUE.UA 
##    0.1713696    0.2226180</code></pre>
<pre class="r"><code>obs_diff_delay &lt;- diffprop(data = flightDelays, Delay &gt;= 20 ~ Carrier)
obs_diff_delay</code></pre>
<pre><code>##   diffprop 
## 0.05124841</code></pre>
<p>We see carrier AA has a 17.13% chance of delays&gt;= 20, while UA has
22.26% chance. The difference is 5.12%. Is this statistically
significant? We take the Delays for both Carriers and perform a
permutation test by <code>shuffle</code> on the <code>carrier</code> variable:</p>
<pre class="r"><code>null_dist_delay &lt;- do(10000) * diffprop(data = flightDelays, Delay &gt;= 20 ~ shuffle(Carrier))
null_dist_delay %&gt;% head()</code></pre>
<pre><code>##       diffprop
## 1  0.008037842
## 2 -0.021592259
## 3 -0.003073446
## 4  0.016679955
## 5 -0.017888497
## 6 -0.006777209</code></pre>
<pre class="r"><code>gf_histogram(data = null_dist_delay, ~ diffprop) %&gt;% gf_vline(xintercept = obs_diff_delay, color = &quot;red&quot;)</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-15-1.png" width="50%" height="50%" /></p>
<p>It appears that the difference indelay times is significant. We can
compute the <code>p-value</code> based on this test:</p>
<pre class="r"><code>2* mean(null_dist_delay &gt;= obs_diff_delay)</code></pre>
<pre><code>## [1] 4e-04</code></pre>
<p>which is very small. Hence we reject the null Hypothesis that there is
no difference between <code>carrier</code>s on <code>delay times</code>.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Compute the variance in the flight delay lengths for each carrier.
Conduct a test to see if the variance for United Airlines differs
from that of American Airlines.</li>
</ol>
<pre class="r"><code>var(data = flightDelays, Delay ~ Carrier)</code></pre>
<pre><code>##       AA       UA 
## 1606.457 2037.525</code></pre>
<pre class="r"><code># There is no readymade function in mosaic called `diffvar`...so...we construct one
obs_diff_var &lt;- diff(var(data = flightDelays, Delay ~ Carrier))
obs_diff_var</code></pre>
<pre><code>##       UA 
## 431.0677</code></pre>
<p>The difference in variances in <code>Delay</code> between the two <code>carrier</code>s is
<span class="math inline">\(-431.0677\)</span>. In our Permutation Test, we <code>shuffle</code> the <code>Carrier</code>
variable:</p>
<pre class="r"><code>obs_diff_var &lt;- diff(var(data = flightDelays, Delay ~ Carrier))
null_dist_var &lt;-
  do(10000) * diff(var(data = flightDelays, Delay ~ shuffle(Carrier)))
null_dist_var %&gt;% head()</code></pre>
<pre><code>##           UA
## 1 -555.97116
## 2  101.87582
## 3  484.84749
## 4  512.76534
## 5  470.19785
## 6   68.31999</code></pre>
<pre class="r"><code># The null distribution variable is called `UA`
gf_histogram(data = null_dist_var, ~ UA) %&gt;% gf_vline(xintercept = obs_diff_delay, color = &quot;red&quot;)</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-18-1.png" width="50%" height="50%" /></p>
<pre class="r"><code>2 * mean(null_dist_var &gt;= obs_diff_var)</code></pre>
<pre><code>## [1] 0.3114</code></pre>
<p>Clearly there is no case for a significant difference in variances!</p>
</div>
<div id="case-study-6-walmart-vs-target" class="section level3">
<h3>Case Study #6: Walmart vs Target</h3>
<p>Is there a difference in the price of groceries sold by the two
retailers Target and Walmart? The data set <code>Groceries</code> contains a sample
of grocery items and their prices advertised on their respective web
sites on one specific day.</p>
<ol style="list-style-type: lower-alpha">
<li>Inspect the data set, then explain why this is an example of matched
pairs data.</li>
<li>Compute summary statistics of the prices for each store.</li>
<li>Conduct a permutation test to determine whether or not there is a
difference in the mean prices.</li>
<li>Create a <del>histogram</del> bar-chart of the difference in prices. What
is unusual about Quaker Oats Life cereal?</li>
<li>Redo the hypothesis test without this observation. Do you reach the
same conclusion?</li>
</ol>
<pre class="r"><code>groceries &lt;- read.csv(&quot;http://sites.google.com/site/chiharahesterberg/data2/Groceries.csv&quot;) %&gt;% mutate(Product = stringr::str_squish(Product))
head(groceries)</code></pre>
<pre><code>##                            Product    Size Target Walmart
## 1          Kellogg NutriGrain Bars  8 bars   2.50    2.78
## 2 Quaker Oats Life Cereal Original    18oz   3.19    6.01
## 3       General Mills Lucky Charms  11.50z   3.19    2.98
## 4        Quaker Oats Old Fashioned    18oz   2.82    2.68
## 5             Nabisco Oreo Cookies 14.3oz    2.99    2.98
## 6               Nabisco Chips Ahoy    13oz   2.64    1.98</code></pre>
<pre class="r"><code>inspect(groceries)</code></pre>
<pre><code>## 
## categorical variables:  
##      name     class levels  n missing                                  distribution
## 1 Product character     30 30       0 Annie&#39;s Macaroni &amp; Cheese (3.3%) ...         
## 2    Size character     24 30       0 18oz (10%), 12oz (6.7%) ...                  
## 
## quantitative variables:  
##      name   class  min     Q1 median    Q3  max     mean       sd  n missing
## 1  Target numeric 0.99 1.8275  2.545 3.140 7.99 2.762333 1.582128 30       0
## 2 Walmart numeric 1.00 1.7600  2.340 2.955 6.98 2.705667 1.560211 30       0</code></pre>
<p>We see that the comparison is to be made between two prices for the
<em>same</em> product, and hence this is one more example of <code>paired data</code>, as
in Case Study #4. Let us plot the prices for the products:</p>
<pre class="r"><code>gf_col(data = groceries,
       Target ~ Product,
       fill = &quot;#0073C299&quot;,
       width = 0.5 ) %&gt;% 
  gf_col(data = groceries,
         -Walmart ~ Product,
         fill = &quot;#EFC00099&quot;,
         ylab = &quot;Prices&quot;,
         width = 0.5
       ) %&gt;% 
  gf_col(data = groceries %&gt;% filter(Product == &quot;Quaker Oats Life Cereal Original&quot;), 
         -Walmart ~ Product,
         fill = &quot;red&quot;, 
         width = 0.5) %&gt;% 
  gf_theme(theme_classic()) %&gt;%
  gf_theme(ggplot2::theme(axis.text.x = element_text(
    size = 8,
    face = &quot;bold&quot;,
    vjust = 0,
    hjust = 1
  ))) %&gt;% gf_theme(ggplot2::coord_flip())</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-20-1.png" width="50%" height="50%" /></p>
<p>We see that the price difference between Walmart and Target prices is
highest for the <code>Product</code> named <code>Quaker Oats Life Cereal Original</code>. Let
us check the mean difference in prices:</p>
<pre class="r"><code>diffmean(data = groceries, Walmart ~ Target, only.2 = FALSE)</code></pre>
<pre><code>##    1-0.99    1.22-1 1.42-1.22 1.49-1.42 1.59-1.49 1.62-1.59 1.79-1.62 1.94-1.79 1.99-1.94 2.12-1.99 2.39-2.12  2.5-2.39  2.59-2.5 
## -0.580000  0.170000  0.210000 -0.100000  0.190000  0.070000  0.180000  0.160000  0.090000  0.010000  0.200000  0.600000 -0.200000 
## 2.64-2.59 2.79-2.64 2.82-2.79 2.99-2.82 3.19-2.99 3.49-3.19 3.99-3.49 4.79-3.99 7.19-4.79 7.99-7.19 
## -0.600000  0.660000  0.040000  0.220000  1.263333 -1.183333 -0.480000  2.290000  2.190000  0.000000</code></pre>
<pre class="r"><code>obs_diff_price = mean( ~ Walmart - Target, data = groceries)
obs_diff_price</code></pre>
<pre><code>## [1] -0.05666667</code></pre>
<p>Let us perform the pair-wise permutation test on prices, by shuffling
the two store names:</p>
<pre class="r"><code>polarity &lt;- c(rep(1, 15), rep(-1,15))
polarity</code></pre>
<pre><code>##  [1]  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1</code></pre>
<pre class="r"><code>null_dist_price &lt;- do(100000) * mean(data = groceries, 
                                    ~(Walmart-Target) * resample(polarity,
                                                    replace = TRUE))
null_dist_price %&gt;% head()</code></pre>
<pre><code>##          mean
## 1  0.16000000
## 2  0.13600000
## 3 -0.05866667
## 4  0.07666667
## 5  0.18200000
## 6  0.13733333</code></pre>
<pre class="r"><code>gf_histogram(data = null_dist_price, ~mean) %&gt;% 
  gf_vline(xintercept = obs_diff_price, colour = &quot;red&quot;)</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-22-1.png" width="50%" height="50%" /></p>
<pre class="r"><code>2*(sum(null_dist_price &gt;= obs_diff_price + 1)/(100000+1)) #P-value</code></pre>
<pre><code>## [1] 0</code></pre>
<p>Does not seem to be aby significant difference in prices…</p>
<p>Suppose we knock off the Quaker Cereal data item…</p>
<pre class="r"><code>which(groceries$Product == &quot;Quaker Oats Life Cereal Original&quot;)</code></pre>
<pre><code>## [1] 2</code></pre>
<pre class="r"><code>groceries_less &lt;- groceries[-2,]
groceries_less</code></pre>
<pre><code>##                                                     Product     Size Target Walmart
## 1                                   Kellogg NutriGrain Bars   8 bars   2.50    2.78
## 3                                General Mills Lucky Charms   11.50z   3.19    2.98
## 4                                 Quaker Oats Old Fashioned     18oz   2.82    2.68
## 5                                      Nabisco Oreo Cookies  14.3oz    2.99    2.98
## 6                                        Nabisco Chips Ahoy     13oz   2.64    1.98
## 7                                Doritos Nacho Cheese Chips     10oz   3.99    2.50
## 8                                   Cheez-it Original Baked     21oz   4.79    4.79
## 9                                  Swiss Miss Hot Chocolate 10 count   1.49    1.28
## 10                        Tazo Chai Classic Latte Black Tea   32 oz    3.49    2.98
## 11                                Annie&#39;s Macaroni &amp; Cheese      6oz   1.79    1.72
## 12                                      Rice A Roni Chicken    6.9oz   1.00    1.00
## 13                            Zatarain&#39;s Jambalaya Rice Mix      8oz   1.62    1.54
## 14                                 SPAM Original Lunch Meat     12oz   2.79    2.64
## 15                           Campbell&#39;s Chicken Noodle Soup  10.75oz   0.99    1.58
## 16                       Dinty Moore Hearty Meals Beef Stew     15oz   1.99    1.98
## 17                                  Hormel Chili with Beans     15oz   1.94    1.88
## 18                                    Dole Pineapple Chunks    20 oz   1.59    1.47
## 19                              Skippy Creamy Peanut Butter   16.3oz   2.59    2.58
## 20                            Smucker&#39;s Strawberry Preserve     18oz   2.99    2.84
## 21                                     Heinz Tomato Ketchup     32oz   2.99    2.88
## 22                 Near East Couscous Toasted Pine Nuts mix    5.6oz   2.12    1.98
## 23                                 Barilla Angel Hair Pasta     16oz   1.42    1.38
## 24       Betty Crocker Super Moist Chocolate Fudge Cake Mix  15.25oz   1.22    1.17
## 25                             Kraft Jet-Puffed Marshmllows     16oz   1.99    1.96
## 26 Dunkin&#39; Donuts Original Blend Medium Roast Ground Coffee     12oz   7.19    6.98
## 27                             Dove Promises Milk Chocolate   8.87oz   3.19    3.50
## 28                                                 Skittles     41oz   7.99    6.98
## 29                         Vlasic Kosher Dill Pickle Spears     24oz   2.39    2.18
## 30                          Vlasic Old Fashioned Sauerkraut     32oz   1.99    1.97</code></pre>
<pre class="r"><code>obs_diff_price_less = mean( ~ Walmart - Target, data = groceries_less)
obs_diff_price_less</code></pre>
<pre><code>## [1] -0.1558621</code></pre>
<pre class="r"><code>polarity_less &lt;- c(rep(1, 15), rep(-1,14)) # Due to resampling this small bias makes no difference
null_dist_price_less &lt;- do(100000) * mean(data = groceries_less, 
                                    ~(Walmart-Target) * resample(polarity_less,
                                                    replace = TRUE))
null_dist_price_less %&gt;% head()</code></pre>
<pre><code>##           mean
## 1  0.012413793
## 2 -0.020000000
## 3  0.050344828
## 4 -0.017241379
## 5 -0.046206897
## 6 -0.008965517</code></pre>
<pre class="r"><code>gf_histogram(data = null_dist_price_less, ~mean) %&gt;% 
  gf_vline(xintercept = obs_diff_price_less, colour = &quot;red&quot;)</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-23-1.png" width="50%" height="50%" /></p>
<pre class="r"><code>1- mean(null_dist_price_less &gt;= obs_diff_price_less) #P-value</code></pre>
<pre><code>## [1] 0.01582</code></pre>
</div>
<div id="case-study-7-proportions-between-categorical-variables" class="section level3">
<h3>Case Study 7: Proportions between Categorical Variables</h3>
<p>Let us try a dataset with Qualitative / Categorical data. This is a
General Social Survey dataset, and we have people with different levels
of <code>Education</code> stating their opinion on the <code>Death Penalty</code>. We want to
know if these two Categorical variables have a correlation, i.e. can the
opinions in favour of the Death Penalty be explained by the Education
level?</p>
<p>Since data is Categorical, we need to take <code>counts</code> in a table, and then
implement a <code>chi-square test</code>. In the test, we will permute the
<code>Education</code> variable to see if we can see how significant its <em>effect
size</em> is.</p>
<pre class="r"><code>GSS2002 &lt;- read.csv(&quot;http://sites.google.com/site/chiharahesterberg/data2/GSS2002.csv&quot;)
inspect(GSS2002)</code></pre>
<pre><code>## 
## categorical variables:  
##             name     class levels    n missing                                  distribution
## 1         Region character      7 2765       0 North Central (24.7%) ...                    
## 2         Gender character      2 2765       0 Female (55.6%), Male (44.4%)                 
## 3           Race character      3 2765       0 White (79.1%), Black (14.8%) ...             
## 4      Education character      5 2760       5 HS (53.8%), Bachelors (16.1%) ...            
## 5        Marital character      5 2765       0 Married (45.9%), Never Married (25.6%) ...   
## 6       Religion character     13 2746      19 Protestant (53.2%), Catholic (24.5%) ...     
## 7          Happy character      3 1369    1396 Pretty happy (57.3%) ...                     
## 8         Income character     24 1875     890 40000-49999 (9.1%) ...                       
## 9       PolParty character      8 2729      36 Ind (19.3%), Not Str Dem (18.9%) ...         
## 10      Politics character      7 1331    1434 Moderate (39.2%), Conservative (15.8%) ...   
## 11     Marijuana character      2  851    1914 Not legal (64%), Legal (36%)                 
## 12  DeathPenalty character      2 1308    1457 Favor (68.7%), Oppose (31.3%)                
## 13        OwnGun character      3  924    1841 No (65.5%), Yes (33.5%) ...                  
## 14        GunLaw character      2  916    1849 Favor (80.5%), Oppose (19.5%)                
## 15 SpendMilitary character      3 1324    1441 About right (46.5%) ...                      
## 16     SpendEduc character      3 1343    1422 Too little (73.9%) ...                       
## 17      SpendEnv character      3 1322    1443 Too little (60%) ...                         
## 18      SpendSci character      3 1266    1499 About right (49.7%) ...                      
## 19        Pres00 character      5 1749    1016 Bush (50.6%), Gore (44.7%) ...               
## 20      Postlife character      2 1211    1554 Yes (80.5%), No (19.5%)                      
## 
## quantitative variables:  
##   name   class min  Q1 median   Q3  max mean       sd    n missing
## 1   ID integer   1 692   1383 2074 2765 1383 798.3311 2765       0</code></pre>
<p>Note how <em>all</em> variables are Categorical !! <code>Education</code> has five
<code>levels</code>:</p>
<pre class="r"><code>GSS2002 %&gt;% count(Education)</code></pre>
<pre><code>##   Education    n
## 1 Bachelors  443
## 2  Graduate  230
## 3        HS 1485
## 4    Jr Col  202
## 5   Left HS  400
## 6      &lt;NA&gt;    5</code></pre>
<pre class="r"><code>GSS2002 %&gt;% count(DeathPenalty)</code></pre>
<pre><code>##   DeathPenalty    n
## 1        Favor  899
## 2       Oppose  409
## 3         &lt;NA&gt; 1457</code></pre>
<p>Let us drop NA entries in Education and Death Penalty. And set up a table for the chi-square test.</p>
<pre class="r"><code>gss2002 &lt;- GSS2002 %&gt;% 
  dplyr::select(Education, DeathPenalty) %&gt;% 
  tidyr::drop_na(., c(Education, DeathPenalty))
dim(gss2002)</code></pre>
<pre><code>## [1] 1307    2</code></pre>
<pre class="r"><code>gss_summary &lt;- gss2002 %&gt;%
  mutate(
    Education = factor(
      Education,
      levels = c(&quot;Bachelors&quot;, &quot;Graduate&quot;, &quot;Jr Col&quot;, &quot;HS&quot;, &quot;Left HS&quot;),
      labels = c(&quot;Bachelors&quot;, &quot;Graduate&quot;, &quot;Jr Col&quot;, &quot;HS&quot;, &quot;Left HS&quot;)
    ),
    DeathPenalty = as.factor(DeathPenalty)
  ) %&gt;%
  group_by(Education, DeathPenalty) %&gt;%
  summarise(count = n()) %&gt;% # This is good for a chisq test
  
  # Add two more columns to faciltate mosaic/Marrimekko Plot
  # 
  mutate(edu_count = sum(count), 
         edu_prop = count / sum(count)) %&gt;%
  ungroup() 

gss_summary</code></pre>
<pre><code>## # A tibble: 10 × 5
##    Education DeathPenalty count edu_count edu_prop
##    &lt;fct&gt;     &lt;fct&gt;        &lt;int&gt;     &lt;int&gt;    &lt;dbl&gt;
##  1 Bachelors Favor          135       206    0.655
##  2 Bachelors Oppose          71       206    0.345
##  3 Graduate  Favor           64       114    0.561
##  4 Graduate  Oppose          50       114    0.439
##  5 Jr Col    Favor           71        87    0.816
##  6 Jr Col    Oppose          16        87    0.184
##  7 HS        Favor          511       711    0.719
##  8 HS        Oppose         200       711    0.281
##  9 Left HS   Favor          117       189    0.619
## 10 Left HS   Oppose          72       189    0.381</code></pre>
<pre class="r"><code># We can plot a heatmap-like `mosaic chart` for this table, using `ggplot`:
# https://stackoverflow.com/questions/19233365/how-to-create-a-marimekko-mosaic-plot-in-ggplot2

ggplot(data = gss_summary, aes( x = Education, y = edu_prop)) +
  geom_bar(aes(width = edu_count, fill = DeathPenalty), stat = &quot;identity&quot;, position = &quot;fill&quot;, colour = &quot;black&quot;) +
  geom_text(aes(label = scales::percent(edu_prop)), position = position_stack(vjust = 0.5)) +


# if labels are desired
 facet_grid(~ Education, scales = &quot;free_x&quot;, space = &quot;free_x&quot;) + 
  theme(scale_fill_brewer(palette = &quot;RdYlGn&quot;)) + 
  # theme(panel.spacing.x = unit(0, &quot;npc&quot;)) + # if no spacing preferred between bars
  theme_void() </code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-26-1.png" width="50%" height="50%" />
Let us now perform the base <code>chisq test</code>: We need a <code>table</code> and then the <code>chisq</code> test:</p>
<pre class="r"><code>gss_table &lt;- tally(DeathPenalty ~ Education, data = gss2002)
gss_table</code></pre>
<pre><code>##             Education
## DeathPenalty Bachelors Graduate  HS Jr Col Left HS
##       Favor        135       64 511     71     117
##       Oppose        71       50 200     16      72</code></pre>
<pre class="r"><code># Get the observed chi-square statistic
observedChi2 &lt;- mosaic::chisq(tally(DeathPenalty ~ Education, data = gss2002))
observedChi2</code></pre>
<pre><code>## X.squared 
##  23.45093</code></pre>
<pre class="r"><code># Actual chi-square test
stats::chisq.test(tally(DeathPenalty ~ Education, data = gss2002))</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tally(DeathPenalty ~ Education, data = gss2002)
## X-squared = 23.451, df = 4, p-value = 0.0001029</code></pre>
<p>We should now repeat the test with permutations on <code>Education</code>:</p>
<pre class="r"><code>null_chisq &lt;- do(10000) * chisq.test(tally(DeathPenalty ~ shuffle(Education), data = gss2002))

head(null_chisq)</code></pre>
<pre><code>##               X.squared df   p.value                     method alternative
## X-squared...1  3.215192  4 0.5224807 Pearson&#39;s Chi-squared test          NA
## X-squared...2  4.413015  4 0.3529866 Pearson&#39;s Chi-squared test          NA
## X-squared...3  1.008265  4 0.9085401 Pearson&#39;s Chi-squared test          NA
## X-squared...4  4.281711  4 0.3692208 Pearson&#39;s Chi-squared test          NA
## X-squared...5  4.231846  4 0.3755373 Pearson&#39;s Chi-squared test          NA
## X-squared...6  1.292480  4 0.8626502 Pearson&#39;s Chi-squared test          NA
##                                                                   data .row .index
## X-squared...1 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1      1
## X-squared...2 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1      2
## X-squared...3 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1      3
## X-squared...4 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1      4
## X-squared...5 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1      5
## X-squared...6 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1      6</code></pre>
<pre class="r"><code>gf_histogram( ~ X.squared, data = null_chisq) %&gt;% 
  gf_vline(xintercept = observedChi2, color = &quot;red&quot;)</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-28-1.png" width="50%" height="50%" /></p>
<pre class="r"><code>gf_histogram( ~ p.value, data = null_chisq, binwidth = 0.1, center = 0.05)</code></pre>
<p><img src="/courses/8-Data-Analytics/20-Basics-of-Modeling/40-Simulation-based-Models/20-Permutation-Tests/files/permutation_files/figure-html/unnamed-chunk-28-2.png" width="50%" height="50%" />
So we would conclude that <code>Education</code> has a significant effect on <code>DeathPenalty</code> opinion!</p>
</div>
</div>
