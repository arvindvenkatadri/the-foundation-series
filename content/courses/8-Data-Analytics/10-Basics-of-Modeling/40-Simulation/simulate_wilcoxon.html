---
title: "Wilcoxon is (almost) a one-sample t-test on signed ranks"
author: "Jonas Kristoffer Lindeløv"
output: 
  html_document:
    df_print: paged
    number_sections: yes
    self_contained: no
    toc: yes
---



<!-- from https://stackoverflow.com/a/37839683/1297830 -->
<link rel="stylesheet" type="text/css" href="../include/hideOutput.css">
<script src="../include/hideOutput.js"></script>
<!--
TO DO:
 * Link to linear-model post
 * Test permutation: coin::wilcox_test()

-->
<p>This document presents the close relationship between the p-values of the Wilcoxon signed-rank test and t-test with signed ranks as dependent variable. It is an appendix to the post “<a href="https://lindeloev.github.io/tests-as-linear">Common statistical tests as linear models</a>”. Since Wilcoxon matched pairs is just the signed-rank on difference scores, the points below apply to that as well.</p>
<p><strong>TL;DR: I argue below that for N &gt; 14, 5the t-test is a reasonable approximation. For N &gt; 50, it is almost exact.</strong></p>
<div id="simple-example" class="section level1">
<h1>Simple example</h1>
<p>First, let’s find a way tocreate some clearly non-normal data. How about this ex-gaussian + uniform values in the negative end:</p>
<pre class="r"><code>weird_data = c(rnorm(10000), exp(rnorm(10000)), runif(10000, min=-3, max=-2))
hist(weird_data, breaks=200, xlim=c(-4, 10))</code></pre>
<p><img src="/courses/8-Data-Analytics/10-Basics-of-Modeling/40-Simulation/simulate_wilcoxon_files/figure-html/example1-1.png" width="672" /></p>
<p>Now, comparing p-values is simple:</p>
<pre class="r"><code>x = sample(weird_data, 50)  # Pick out a few values to get reasonable p-values
signed_ranks = sign(x) * rank(abs(x))
p_wilcox = wilcox.test(x)$p.value
p_ttest = t.test(signed_ranks)$p.value
rbind(p_wilcox, p_ttest)  # Print in rows</code></pre>
<pre><code>##                [,1]
## p_wilcox 0.06955213
## p_ttest  0.06829937</code></pre>
<p>OK, so they are close in this example. But was this just luck and a special case of N=50?</p>
</div>
<div id="simulation" class="section level1">
<h1>Simulation</h1>
<p>Let’s do what we did above, but running a few thousand simulations for different N and means (<code>mu</code>):</p>
<pre class="r"><code>library(tidyverse)
signed_rank = function(x) sign(x) * rank(abs(x))

# Parameters
Ns = c(seq(from=6, to=20, by=2), 30, 50, 80)
mus = c(0, 1, 2)  # Means
PERMUTATIONS = 1:200

# Run it
D = expand.grid(set=PERMUTATIONS, mu=mus, N=Ns) %&gt;%
  mutate(
    # Generate data
    data = map2(mu, N, function(mu, N) mu + sample(weird_data, N)),
    
    # Run tests
    wilcox_raw = map(data, ~ wilcox.test(.x)),
    ttest_raw = map(data, ~ t.test(signed_rank(.x))),
    
    # Tidy it up
    wilcox = map(wilcox_raw, broom::tidy),
    ttest = map(ttest_raw, broom::tidy)
  ) %&gt;%
  
  # Get as columns instead of lists; then remove &quot;old&quot; columns
  unnest(wilcox, ttest, .sep=&#39;_&#39;) %&gt;%
  select(-data, -wilcox_raw, -ttest_raw)

head(D)</code></pre>
<pre><code>## # A tibble: 6 × 15
##     set    mu     N wilcox_statistic wilcox_p.va…¹ wilco…² wilco…³ ttest…⁴ ttest…⁵ ttest…⁶ ttest…⁷ ttest…⁸ ttest…⁹ ttest…˟ ttest…˟
##   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  
## 1     1     0     6                3        0.156  Wilcox… two.si…  -2.5   -1.87    0.120        5   -5.93   0.933 One Sa… two.si…
## 2     2     0     6               11        1      Wilcox… two.si…   0.167  0.0958  0.927        5   -4.31   4.64  One Sa… two.si…
## 3     3     0     6                3        0.156  Wilcox… two.si…  -2.5   -1.87    0.120        5   -5.93   0.933 One Sa… two.si…
## 4     4     0     6               12        0.844  Wilcox… two.si…   0.5    0.289   0.784        5   -3.94   4.94  One Sa… two.si…
## 5     5     0     6                2        0.0938 Wilcox… two.si…  -2.83  -2.37    0.0639       5   -5.90   0.238 One Sa… two.si…
## 6     6     0     6                8        0.688  Wilcox… two.si…  -0.833 -0.490   0.645        5   -5.21   3.54  One Sa… two.si…
## # … with abbreviated variable names ¹​wilcox_p.value, ²​wilcox_method, ³​wilcox_alternative, ⁴​ttest_estimate, ⁵​ttest_statistic,
## #   ⁶​ttest_p.value, ⁷​ttest_parameter, ⁸​ttest_conf.low, ⁹​ttest_conf.high, ˟​ttest_method, ˟​ttest_alternative</code></pre>
<p>Let’s take a look at how the p-values from the “ranked t-test” compare to Wilcoxon p-values:</p>
<div class="fold s">
<pre class="r"><code>D$N = factor(D$N)  # Make N a factor for prettier plotting

library(ggplot2)
library(patchwork)

# A straight-up comparison of the p-values
p_relative = ggplot(D, aes(x=wilcox_p.value, y=ttest_p.value, color=N)) + 
  geom_line() + 
  geom_vline(xintercept=0.05, lty=2) +
  geom_hline(yintercept=0.05, lty=2) +
  
  labs(title=&#39;Absolute relation&#39;, x = &#39;Wilcoxon p-value&#39;, y = &#39;T-test p-value&#39;) + 
  #coord_cartesian(xlim=c(0, 0.10), ylim=c(0, 0.11)) + 
  theme_gray(13) + 
  guides(color=FALSE)</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; = &quot;none&quot;)` instead.</code></pre>
<pre class="r"><code># Looking at the difference (error) between p-values
p_error_all = ggplot(D, aes(x=wilcox_p.value, y=ttest_p.value-wilcox_p.value, color=N)) + 
  geom_line() + 
  geom_vline(xintercept=0.05, lty=2) +
  
  labs(title=&#39;Error&#39;, x = &#39;Wilcoxon p-value&#39;, y = &#39;T-test p-value deviation&#39;) + 
  theme_gray(13) + 
  guides(color=FALSE)</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; = &quot;none&quot;)` instead.</code></pre>
<pre class="r"><code># Same, but zoomed in around p=0.05
p_error_zoom = ggplot(D, aes(x=wilcox_p.value, y=ttest_p.value-wilcox_p.value, color=N)) + 
  geom_line() + 
  geom_vline(xintercept=0.05, lty=2) +
  
  labs(title=&#39;Zoomed error&#39;, x = &#39;Wilcoxon p-value&#39;, y = &#39;T-test p-value deviation&#39;) + 
  coord_cartesian(xlim=c(0, 0.10), ylim=c(-0.020, 0.000)) + 
  theme_gray(13)

# Show it. Patchwork is your friend!
p_relative + p_error_all + p_error_zoom</code></pre>
<p><img src="/courses/8-Data-Analytics/10-Basics-of-Modeling/40-Simulation/simulate_wilcoxon_files/figure-html/unnamed-chunk-1-1.png" width="960" /></p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>The “signed rank t-test”” underestimates p (it is too liberal), but I would say that this deviance is acceptable for N &gt; 14, i.e. where the error is at most 0.5% in the “critical” region around p=5%. N Needs to exceed 30 before p becomes virtually identical to Wilcoxon (difference less than 0.2%).</p>
<p>In further testing, I found that the p-value curves are not affected by simply shifting the data away from the test value, thus lowering the means. Similarly, the overall shape is similar for various crazy and non-crazy distributions. For simplicity, I have unfolded this here.</p>
<p>It has also been <a href="http://andrewgelman.com/2015/07/13/dont-do-the-wilcoxon/#comment-226251">suggested to use Z-transforms of the ranks</a>, though I’ve found this to introduce larger differences in p-values.</p>
</div>
